
"""
LSTM å¤šè¾“å…¥é¢„æµ‹è„šæœ¬
ç›´æ¥è¿è¡Œå³å¼€å§‹è®­ç»ƒã€‚
åˆ©ç”¨æ—©åœã€Dropoutã€L2æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

"""

import os
import json
import random
import ast
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import wandb
from typing import Dict, Tuple, List
from tensorflow.keras.layers import (Input, Dense, Dropout, Embedding, Flatten,
                                     LSTM, Concatenate)
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, Callback
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score
from predict import plot_roc_curve, plot_scatter
from tensorflow.keras.regularizers import l2 


# ==========================================================
# å…¨å±€é…ç½®
# ==========================================================

# æ•°æ®é›†å’Œç‰¹å¾æ–‡ä»¶è·¯å¾„
TRAIN_FILE = "dataset/train_data.csv"
VAL_FILE = "dataset/val_data.csv"
TEST_FILE = "dataset/test_data.csv"
PLAYER_FILE = "dataset/player_data.csv" 
DIFFICULTY_FILE = "dataset/difficulty_data.csv"

# æ¨¡å‹å’ŒæŠ¥å‘Šè¾“å‡ºè·¯å¾„
MODEL_SAVE_PATH = "models/lstm/lstm_model.keras"
TOKENIZER_PATH = "models/lstm/lstm_tokenizer.json"
REPORT_SAVE_PATH = "outputs/lstm_output.txt"

# è®­ç»ƒåŸºæœ¬å‚æ•°
LOOK_BACK = 5
BATCH_SIZE = 1024
EPOCHS = 40
LEARNING_RATE = 0.0005
LARGE_ERROR_THRESHOLD = 1.5

# LSTM æ¶æ„å‚æ•°
LSTM_UNITS = 56
DROPOUT_RATE = 0.45 
EMBEDDING_DIM = 24

# è¯å…¸å‚æ•°
OOV_TOKEN = "<OOV>"

# æ—©åœå€¼
PATIENCE = 4

# æŸå¤±å‡½æ•°æƒé‡
LOSS_WEIGHTS = {"output_steps": 0.8, "output_success": 1}

# Focal Loss è¶…å‚æ•°
FOCAL_LOSS_ALPHA = 0.25
FOCAL_LOSS_GAMMA = 2.0

# L2 æ­£åˆ™åŒ–ç³»æ•°
L2_REG_FACTOR = 0.001 

# å›ºå®šéšæœºç§å­
SEED = 42

# Wordleå›ºå®šå‚æ•°
MAX_TRIES = 6
GRID_FEAT_LEN = 8 # 3ä¸ªç´¯ç§¯é¢œè‰²ç‰¹å¾ + 5ä¸ªä½ç½®ç»¿è‰²ç‰¹å¾

# --------------------------
# åŸºæœ¬å‡½æ•°
# --------------------------
def set_seed(seed):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

def ensure_dirs():
    os.makedirs(os.path.dirname(MODEL_SAVE_PATH) or ".", exist_ok=True)
    os.makedirs("outputs", exist_ok=True)
    os.makedirs("models/lstm", exist_ok=True)
    os.makedirs("visualization", exist_ok=True)

def safe_read_csv(path, usecols=None):
    if not os.path.exists(path):
        raise FileNotFoundError(f"File missing: {path}")
    return pd.read_csv(path, usecols=usecols)

# --------------------------
# ç½‘æ ¼åºåˆ—è§£æå™¨
# --------------------------
def encode_guess_sequence(grid_cell):
    """
    å°† grid åˆ—è¡¨è½¬æ¢ä¸ºä¸€ä¸ªæ—¶é—´åºåˆ—ç‰¹å¾çŸ©é˜µã€‚
    è¿”å›å½¢çŠ¶ä¸º (MAX_TRIES, GRID_FEAT_LEN) çš„æµ®ç‚¹çŸ©é˜µã€‚
    ä¸Transformeræ¨¡å‹ä½¿ç”¨ç›¸åŒçš„8ç»´ç´¯ç§¯ç‰¹å¾ï¼š
    1. ç´¯ç§¯ç»¿è‰²æ–¹å—æ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
    2. ç´¯ç§¯é»„è‰²æ–¹å—æ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
    3. ç´¯ç§¯ç°è‰²æ–¹å—æ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
    4-8. æ¯ä¸ªä½ç½®ç´¯ç§¯ç»¿è‰²æ–¹å—æ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
    """
    default_seq = np.zeros((MAX_TRIES, GRID_FEAT_LEN), dtype=np.float32)
    if pd.isna(grid_cell):
        return default_seq
    try:
        if isinstance(grid_cell, (list, tuple)):
            grid_list = list(grid_cell)
        else:
            grid_list = ast.literal_eval(grid_cell)
            if not isinstance(grid_list, (list, tuple)):
                grid_list = [grid_list]
            grid_list = [str(r) for r in grid_list if isinstance(r, (str, bytes))]
    except Exception:
        return default_seq

    num_rows = len(grid_list)
    cumulative_greens = 0
    cumulative_yellows = 0
    cumulative_grays = 0
    cumulative_pos_green_counts = np.zeros(5, dtype=np.float32)
    feature_sequence = np.zeros((MAX_TRIES, GRID_FEAT_LEN), dtype=np.float32)
    norm_base_cells = float(MAX_TRIES * 5)
    norm_base_rows = float(MAX_TRIES)

    for t in range(MAX_TRIES):
        if t < num_rows:
            row = grid_list[t]
            greens_t, yellows_t, grays_t = 0, 0, 0
            pos_green_counts_t = np.zeros(5, dtype=np.float32)
            if isinstance(row, str) and len(row) == 5:
                for i, ch in enumerate(row):
                    if ch == "ğŸŸ©":
                        greens_t += 1
                        pos_green_counts_t[i] += 1.0
                    elif ch == "ğŸŸ¨":
                        yellows_t += 1
                    elif ch == "â¬œ" or ch == "â¬›":
                        grays_t += 1
            cumulative_greens += greens_t
            cumulative_yellows += yellows_t
            cumulative_grays += grays_t
            cumulative_pos_green_counts += pos_green_counts_t

        feat = np.zeros(GRID_FEAT_LEN, dtype=np.float32)
        feat[0] = cumulative_greens / norm_base_cells
        feat[1] = cumulative_yellows / norm_base_cells
        feat[2] = cumulative_grays / norm_base_cells
        for i in range(5):
            feat[3 + i] = cumulative_pos_green_counts[i] / norm_base_rows
        feature_sequence[t] = feat

    return feature_sequence


# --------------------------
# Tokenizer
# --------------------------
def fit_tokenizer(train_df):
    tokenizer = Tokenizer(oov_token=OOV_TOKEN, filters='', lower=True)
    tokenizer.fit_on_texts(train_df["target"].astype(str))
    with open(TOKENIZER_PATH, "w", encoding="utf-8") as f:
        json.dump(tokenizer.word_index, f, indent=2)
    return tokenizer

def load_tokenizer():
    with open(TOKENIZER_PATH, "r", encoding="utf-8") as f:
        word_index = json.load(f)
    tk = Tokenizer(oov_token=OOV_TOKEN)
    tk.word_index = word_index
    return tk

# --------------------------
# å•è¯éš¾åº¦ã€ç”¨æˆ·åç½®ç‰¹å¾é™„åŠ 
# --------------------------
def attach_features(df, tokenizer, user_map, diff_map):
    df = df.copy()
    df["target"] = df["target"].astype(str)
    # å•è¯ id
    seqs = tokenizer.texts_to_sequences(df["target"])
    df["word_id"] = [s[0] if s else 0 for s in seqs]
    # æ·»åŠ å•è¯éš¾åº¦
    df["word_difficulty"] = df["target"].map(diff_map).fillna(4.0).astype(float)
    df["user_bias"] = df["Username"].map(user_map).fillna(4.0).astype(float)
    # è§£æ grid åºåˆ—
    if "processed_text" in df.columns:
        df["grid_seq"] = df["processed_text"].apply(encode_guess_sequence)
    else:
        # ç¼ºå¤±æ—¶è¿”å›é›¶åºåˆ—
        df["grid_seq"] = [np.zeros((MAX_TRIES, GRID_FEAT_LEN), dtype=np.float32) for _ in range(len(df))]

    return df

# ==========================================================
# æŸå¤±å‡½æ•° (Focal Loss å®šä¹‰)
# ==========================================================

def focal_loss(gamma=2.0, alpha=0.25):
    """
    Focal Loss for Binary Classification (sigmoid output).
    Reference: Lin et al., 2017.
    """
    gamma = float(gamma)
    alpha = float(alpha)

    def focal_loss_fixed(y_true, y_pred):
        # è£å‰ª y_pred ä»¥é¿å… log(0)
        epsilon = tf.keras.backend.epsilon()
        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)

        # è®¡ç®—äº¤å‰ç†µ
        bce = y_true * tf.math.log(y_pred)
        bce += (1 - y_true) * tf.math.log(1 - y_pred)
        bce = -bce

        # è®¡ç®—è°ƒåˆ¶å› å­
        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)
        modulating_factor = tf.pow(1.0 - p_t, gamma)

        # ä¹˜ä»¥æƒé‡é¡¹
        alpha_factor = y_true * alpha + (1 - y_true) * (1.0 - alpha)

        # Focal Loss = alpha_factor * modulating_factor * BCE
        focal_loss = alpha_factor * modulating_factor * bce
        
        return tf.reduce_mean(focal_loss)

    focal_loss_fixed.__name__ = f'focal_loss(gamma={gamma},alpha={alpha})'
    return focal_loss_fixed


# --------------------------
# å†å²å»ºè¡¨
# --------------------------
def build_history(df) -> Dict[str, List[Tuple]]:
    hist = {}
    df_sorted = df.sort_values(["Username", "Game"])
    for u, g in df_sorted.groupby("Username", sort=False):
        # å†å²è®°å½• tuple ç»“æ„ï¼š(Trial, word_id, user_bias, word_difficulty, grid_seq)
        hist[u] = [(int(r["Trial"]),
                    int(r["word_id"]),
                    float(r["user_bias"]),
                    float(r["word_difficulty"]), 
                    np.array(r["grid_seq"], dtype=np.float32))
                   for _, r in g.iterrows()]
    return hist

# --------------------------
# æ»‘çª—ç”Ÿæˆæ ·æœ¬
# --------------------------
def create_samples(history, look_back):
    X_seq, X_wid, X_bias, X_diff, X_grid_seq, y_steps, y_succ = [], [], [], [], [], [], []
    for _, events in history.items():
        if len(events) <= look_back:
            continue
        for i in range(look_back, len(events)):
            window = events[i-look_back:i]
            target = events[i]

            trials = np.array([t[0] for t in window], np.float32)
            norm = trials / 7.0
            std = np.std(trials) / 7.0

            seq = np.stack([norm, np.full_like(norm, std)], axis=1)
            X_seq.append(seq)
            # å•è¯ ID
            X_wid.append([target[1]])
            # ç”¨æˆ·åç½®
            X_bias.append([target[2] / 7.0])
            # å•è¯éš¾åº¦
            X_diff.append([target[3] / 7.0])
            # åºåˆ—ç‰¹å¾
            X_grid_seq.append(target[4]) 

            y_steps.append(min(float(target[0]), 7.0))
            y_succ.append(1.0 if target[0] <= 6 else 0.0)

    if not X_seq:
        return (np.zeros((0, look_back, 2), np.float32),
                np.zeros((0, 1), np.int32),
                np.zeros((0, 1), np.float32),
                np.zeros((0, 1), np.float32),
                np.zeros((0, MAX_TRIES, GRID_FEAT_LEN), np.float32), 
                np.zeros((0,), np.float32),
                np.zeros((0,), np.float32))

    return (
        np.array(X_seq, np.float32),
        np.array(X_wid, np.int32),
        np.array(X_bias, np.float32),
        np.array(X_diff, np.float32),
        np.array(X_grid_seq, np.float32),
        np.array(y_steps, np.float32),
        np.array(y_succ, np.float32)
    )

# ==========================================================
# LSTM æ¨¡å‹æ„å»º
# ==========================================================
def build_model(look_back, vocab_size):
    # å†å²è¾“å…¥åˆ†æ”¯
    h_in = Input((look_back, 2), name="input_history")
    x = LSTM(LSTM_UNITS, kernel_regularizer=l2(L2_REG_FACTOR))(h_in)
    x = Dropout(DROPOUT_RATE)(x)

    # å•è¯ ID
    wid_in = Input((1,), name="input_word_id", dtype="int32")
    wemb = Flatten()(Embedding(vocab_size, EMBEDDING_DIM)(wid_in))

    # ç”¨æˆ·åç½®
    bias_in = Input((1,), name="input_user_bias")
    b1 = Dense(16, activation="relu", kernel_regularizer=l2(L2_REG_FACTOR))(bias_in)

    # å•è¯éš¾åº¦
    diff_in = Input((1,), name="input_difficulty")
    d1 = Dense(16, activation="relu", kernel_regularizer=l2(L2_REG_FACTOR))(diff_in)

    # Wordle åºåˆ—ç‰¹å¾
    grid_seq_in = Input((MAX_TRIES, GRID_FEAT_LEN), name="input_grid_sequence")
    g_seq = LSTM(LSTM_UNITS // 4, kernel_regularizer=l2(L2_REG_FACTOR))(grid_seq_in)
    g_seq = Dropout(DROPOUT_RATE)(g_seq)
    g2 = Dense(16, activation="relu", kernel_regularizer=l2(L2_REG_FACTOR))(g_seq)

    # åˆå¹¶ç‰¹å¾
    z = Concatenate()([x, wemb, b1, d1, g2])
    z = Dense(64, activation="relu", kernel_regularizer=l2(L2_REG_FACTOR))(z)
    z = Dropout(DROPOUT_RATE)(z)

    # å›å½’å¤´ï¼ˆé¢„æµ‹æ­¥æ•°ï¼‰
    out_steps = Dense(1, "linear", name="output_steps")(Dense(32, "relu", kernel_regularizer=l2(L2_REG_FACTOR))(z))

    # success head
    succ = Dense(64, activation="relu", kernel_regularizer=l2(L2_REG_FACTOR))(z)
    succ = Dropout(0.45)(succ) # <--- é—œéµä¿®æ”¹ï¼šå¾ 0.3 èª¿æ•´ç‚º 0.45
    succ = Dense(32, activation="relu", kernel_regularizer=l2(L2_REG_FACTOR))(succ)
    out_succ = Dense(1, activation="sigmoid", name="output_success")(succ)

    # ç¼–è¯‘
    model = Model(
        [h_in, wid_in, bias_in, diff_in, grid_seq_in],
        [out_steps, out_succ]
    )

    model.compile(
        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),

        # ä½¿ç”¨ Focal Loss
        loss={
            "output_steps": "mae",
            "output_success": focal_loss(alpha=FOCAL_LOSS_ALPHA, gamma=FOCAL_LOSS_GAMMA)
        },
        loss_weights=LOSS_WEIGHTS,
        metrics={"output_success": "accuracy"}
    )

    return model

# ==========================================================
# è¯„ä¼°å‡½æ•°
# ==========================================================
def evaluate_model(model, Xs):
    # Xs ç»“æ„: (seq, wid, bias, diff, grid_seq, y_steps, y_succ)
    X_seq, X_wid, X_bias, X_diff, X_grid_seq, y_steps, y_succ = Xs

    pred_steps, pred_prob = model.predict({
        "input_history": X_seq,
        "input_word_id": X_wid,
        "input_user_bias": X_bias,
        "input_difficulty": X_diff,
        "input_grid_sequence": X_grid_seq
    }, batch_size=1024, verbose=1)

    pred_steps = pred_steps.flatten()
    pred_prob = pred_prob.flatten()

    mae = mean_absolute_error(y_steps, np.clip(pred_steps, 0, 7))
    rmse = np.sqrt(mean_squared_error(y_steps, np.clip(pred_steps, 0, 7)))
    acc = accuracy_score(y_succ.astype(int), (pred_prob >= 0.5).astype(int))

    # ä½¿ç”¨ä»predict.pyå¯¼å…¥çš„calculate_auc_bestå‡½æ•°
    from predict import calculate_auc_best
    auc_value, _, _ = calculate_auc_best(y_succ, pred_prob)
    auc = auc_value

    print(f"MAE={mae:.4f}, RMSE={rmse:.4f}, ACC={acc:.4f}, AUC={auc:.4f}")
    return mae, rmse, acc, auc


def compute_large_error_rate(y_true, y_pred, threshold):
    errors = np.abs(y_true - y_pred)
    return np.mean(errors > threshold)

def plot_loss(history, save_path_base):
    # ç¡®ä¿ä¿å­˜è·¯å¾„æ˜¯æ–‡ä»¶å¤¹ï¼Œä»¥ä¾¿ä¿å­˜å¤šä¸ªæ–‡ä»¶
    save_dir = os.path.dirname(save_path_base) or "."
    
    # -------------------
    # å›¾ 1: Training and Validation Loss (æ€»æŸå¤± - ä¿æŒä¸å˜)
    # -------------------
    plt.figure(figsize=(6, 6))
    plt.plot(history.history['loss'], label='Training Total Loss')
    if 'val_loss' in history.history:
        plt.plot(history.history['val_loss'], label='Validation Total Loss')
    plt.title('Training and Validation Total Loss (Weighted)')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    total_loss_path = os.path.join(save_dir, "LSTM_total_loss_curve.png")
    plt.savefig(total_loss_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Total Loss curve saved to: {total_loss_path}")
    
    # -------------------
    # å›¾ 2: Steps Loss (å›å½’ä»»åŠ¡ - MAE)
    # -------------------
    plt.figure(figsize=(6, 6))
    if 'output_steps_loss' in history.history:
        plt.plot(history.history['output_steps_loss'], label='Training Steps Loss')
        if 'val_output_steps_loss' in history.history:
            plt.plot(history.history['val_output_steps_loss'], label='Validation Steps Loss')
    plt.title('Steps Prediction Component Loss (MAE)')
    plt.xlabel('Epochs')
    plt.ylabel('Loss (MAE)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    steps_loss_path = os.path.join(save_dir, "LSTM_steps_loss_curve.png")
    plt.savefig(steps_loss_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Steps Loss curve saved to: {steps_loss_path}")

    # -------------------
    # å›¾ 3: Success Loss (åˆ†ç±»ä»»åŠ¡ - Focal Loss)
    # -------------------
    plt.figure(figsize=(6, 6))
    if 'output_success_loss' in history.history:
        plt.plot(history.history['output_success_loss'], label='Training Success Loss')
        if 'val_output_success_loss' in history.history:
            plt.plot(history.history['val_output_success_loss'], label='Validation Success Loss')
    plt.title('Success Prediction Component Loss (Focal Loss)')
    plt.xlabel('Epochs')
    plt.ylabel('Loss (Focal Loss)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    success_loss_path = os.path.join(save_dir, "LSTM_success_loss_curve.png")
    plt.savefig(success_loss_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Success Loss curve saved to: {success_loss_path}")

# ==========================================================
# WandB-safe Keras Callback
# ==========================================================
class WandbEpochLogger(Callback):
    def __init__(self):
        super().__init__()

    def on_epoch_end(self, epoch, logs=None):
        if logs is None:
            logs = {}
        metrics = {k: float(v) for k, v in logs.items()}
        metrics["epoch"] = int(epoch)
        wandb.log(metrics, step=epoch)

# ==========================================================
# ä¸»ç¨‹åº
# ==========================================================
def main_train():
    set_seed(SEED)
    ensure_dirs()

    # WandB åˆå§‹åŒ–
    wandb.init(
        project="word-difficulty-prediction",
        name="lstm-model-grid-seq-run",
        config={
            "model_type": "LSTM_Grid_Seq_Simplified",
            "look_back": LOOK_BACK,
            "batch_size": BATCH_SIZE,
            "epochs": EPOCHS,
            "learning_rate": LEARNING_RATE,
            "lstm_units": LSTM_UNITS,
            "dropout_rate": DROPOUT_RATE,
            "embedding_dim": EMBEDDING_DIM,
            "seed": SEED,
            "GRID_FEAT_LEN": GRID_FEAT_LEN # æ–°å¢é…ç½®
        },
        settings=wandb.Settings(_disable_stats=True)
    )

    try:
        if hasattr(wandb.run, "summary") and "graph" in wandb.run.summary:
            wandb.run.summary.pop("graph", None)
    except Exception:
        pass

    # 1. æ•°æ®è¯»å–
    use_cols_list = ["Game", "Trial", "Username", "target", "processed_text"]
    train_df = safe_read_csv(TRAIN_FILE, usecols=use_cols_list)
    val_df = safe_read_csv(VAL_FILE, usecols=use_cols_list)
    test_df = safe_read_csv(TEST_FILE, usecols=use_cols_list)

    # 2. éš¾åº¦/ç”¨æˆ·æ°´å¹³
    user_map = {}
    if os.path.exists(PLAYER_FILE):
        pdf = pd.read_csv(PLAYER_FILE)
        user_map = dict(zip(pdf["Username"], pdf["avg_trial"]))
    
    # åŠ è½½å•è¯éš¾åº¦æ•°æ®
    diff_map = {}
    if os.path.exists(DIFFICULTY_FILE):
        df_diff = pd.read_csv(DIFFICULTY_FILE)
        # ä½¿ç”¨å¹³å‡å°è¯•æ¬¡æ•°ä½œä¸ºéš¾åº¦å€¼
        diff_map = dict(zip(df_diff["word"], df_diff["avg_trial"]))

    # 3. Tokenizer
    tokenizer = fit_tokenizer(train_df)

    # 4. é™„åŠ ç‰¹å¾
    train_df = attach_features(train_df, tokenizer, user_map, diff_map)
    val_df = attach_features(val_df, tokenizer, user_map, diff_map)
    test_df = attach_features(test_df, tokenizer, user_map, diff_map)

    # 5. æ„å»ºç”¨æˆ·å†å²è¡Œä¸ºåºåˆ—
    hist_train = build_history(train_df)
    hist_val = build_history(val_df)
    hist_test = build_history(test_df)

    # 6. Sliding samples
    # X_set ç»“æ„ï¼š(seq, wid, bias, grid_seq, y_steps, y_succ)
    X_train = create_samples(hist_train, LOOK_BACK)
    X_val = create_samples(hist_val, LOOK_BACK)
    X_test = create_samples(hist_test, LOOK_BACK)

    print(f"Train={len(X_train[0])}, Val={len(X_val[0])}, Test={len(X_test[0])}")

    vocab_size = len(tokenizer.word_index) + 1

    # 7. æ¨¡å‹æ„å»º
    model = build_model(LOOK_BACK, vocab_size)
    model.summary()

    # 8. TF dataset
    train_ds = tf.data.Dataset.from_tensor_slices((
        {
            "input_history": X_train[0],
            "input_word_id": X_train[1],
            "input_user_bias": X_train[2],
            "input_difficulty": X_train[3],
            "input_grid_sequence": X_train[4]
        },
        {
            "output_steps": X_train[5],
            "output_success": X_train[6]
        }
    )).shuffle(20000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    val_ds = tf.data.Dataset.from_tensor_slices((
        {
            "input_history": X_val[0],
            "input_word_id": X_val[1],
            "input_user_bias": X_val[2],
            "input_difficulty": X_val[3],
            "input_grid_sequence": X_val[4]
        },
        {
            "output_steps": X_val[5],
            "output_success": X_val[6]
        }
    )).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # 9. è®­ç»ƒ
    early = EarlyStopping(monitor="val_loss", patience=PATIENCE, restore_best_weights=True)
    wandb_logger = WandbEpochLogger()

    train_history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=[early, wandb_logger]
    )

    # ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±æ›²çº¿
    loss_curve_path = "visualization/LSTM_loss_curve.png"
    plot_loss(train_history, loss_curve_path)

    try:
        wandb.log({"loss_curve": wandb.Image(loss_curve_path)})
    except Exception:
        pass

    model.save(MODEL_SAVE_PATH)
    print(f"Model saved to {MODEL_SAVE_PATH}")

    # éªŒè¯è¯„ä¼°
    print("\n=== Validation ===")
    # X_val ç»“æ„: (seq, wid, bias, diff, grid_seq, y_steps, y_succ)
    val_mae, val_rmse, val_acc, val_auc = evaluate_model(model, X_val)

    # è®°å½•éªŒè¯é›†æŒ‡æ ‡åˆ°wandb
    wandb.log({
        "val_mae": val_mae,
        "val_rmse": val_rmse,
        "val_accuracy": val_acc,
        "val_auc": val_auc
    })

    # ç»˜åˆ¶éªŒè¯é›†ROCæ›²çº¿
    val_pred_steps, val_pred_prob = model.predict({
        "input_history": X_val[0],
        "input_word_id": X_val[1],
        "input_user_bias": X_val[2],
        "input_difficulty": X_val[3],
        "input_grid_sequence": X_val[4]
    }, batch_size=1024, verbose=0)
    val_roc_curve_path = "visualization/LSTM_validation_roc_curve.png"
    plot_roc_curve(X_val[6], val_pred_prob.flatten(), val_roc_curve_path)
    
    # ç»˜åˆ¶éªŒè¯é›†æ•£ç‚¹å›¾
    val_scatter_path = "visualization/LSTM_validation_scatter.png"
    plot_scatter(X_val[5], np.clip(val_pred_steps.flatten(), 0, 7), val_scatter_path, model_name="LSTM")
    
    try:
        wandb.log({"validation_roc_curve": wandb.Image(val_roc_curve_path), "validation_scatter": wandb.Image(val_scatter_path)})
    except Exception:
        pass

    # æµ‹è¯•è¯„ä¼°
    print("\n=== Test ===")
    test_mae, test_rmse, test_acc, test_auc = evaluate_model(model, X_test)

    wandb.log({
        "test_mae": test_mae,
        "test_rmse": test_rmse,
        "test_accuracy": test_acc,
        "test_auc": test_auc
    })

    # ç»˜åˆ¶æµ‹è¯•é›†ROCæ›²çº¿
    test_pred_steps, test_pred_prob = model.predict({
        "input_history": X_test[0],
        "input_word_id": X_test[1],
        "input_user_bias": X_test[2],
        "input_difficulty": X_test[3],
        "input_grid_sequence": X_test[4]
    }, batch_size=1024, verbose=0)
    test_roc_curve_path = "visualization/LSTM_test_roc_curve.png"
    plot_roc_curve(X_test[6], test_pred_prob.flatten(), test_roc_curve_path)
    
    # ç»˜åˆ¶æµ‹è¯•é›†æ•£ç‚¹å›¾
    test_scatter_path = "visualization/LSTM_test_scatter.png"
    plot_scatter(X_test[5], np.clip(test_pred_steps.flatten(), 0, 7), test_scatter_path, model_name="LSTM")
    
    try:
        wandb.log({"test_roc_curve": wandb.Image(test_roc_curve_path), "test_scatter": wandb.Image(test_scatter_path)})
    except Exception:
        pass

    # ç”Ÿæˆå¤§å‹è¯¯å·®ç»Ÿè®¡
    val_pred_steps, _ = model.predict({
        "input_history": X_val[0],
        "input_word_id": X_val[1],
        "input_user_bias": X_val[2],
        "input_difficulty": X_val[3],
        "input_grid_sequence": X_val[4]
    }, batch_size=1024, verbose=0)
    val_pred_steps = val_pred_steps.flatten()
    val_large_error_rate = compute_large_error_rate(X_val[5], np.clip(val_pred_steps, 0, 7), LARGE_ERROR_THRESHOLD)

    test_pred_steps, _ = model.predict({
        "input_history": X_test[0],
        "input_word_id": X_test[1],
        "input_user_bias": X_test[2],
        "input_difficulty": X_test[3],
        "input_grid_sequence": X_test[4]
    }, batch_size=1024, verbose=0)
    test_pred_steps = test_pred_steps.flatten()
    test_large_error_rate = compute_large_error_rate(X_test[5], np.clip(test_pred_steps, 0, 7), LARGE_ERROR_THRESHOLD)

    # æ ¼å¼åŒ–æŠ¥å‘Š
    report = f"""
========================================
 LSTM Model Validation and Test Report 
========================================
---- Validation Set Metrics ----
1. Mean Absolute Error (MAE)    : {val_mae:.4f}
2. Root Mean Squared Error (RMSE)     : {val_rmse:.4f}
3. Win/Loss Prediction Accuracy        : {val_acc:.3%}
4. Area Under ROC Curve (AUC)   : {val_auc:.4f}
5. Large Error Rate (>{LARGE_ERROR_THRESHOLD} steps)  : {val_large_error_rate:.3%}

---- Test Set Metrics ----
1. Mean Absolute Error (MAE)    : {test_mae:.4f}
2. Root Mean Squared Error (RMSE)     : {test_rmse:.4f}
3. Win/Loss Prediction Accuracy        : {test_acc:.3%}
4. Area Under ROC Curve (AUC)   : {test_auc:.4f}
5. Large Error Rate (>{LARGE_ERROR_THRESHOLD} steps)  : {test_large_error_rate:.3%}
========================================
"""

    with open(REPORT_SAVE_PATH, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nğŸ“„ Report saved to: {REPORT_SAVE_PATH}")
    print(report)

    wandb.log({
        "val_large_error_rate": val_large_error_rate,
        "test_large_error_rate": test_large_error_rate
    })

    # ç»“æŸ wandb è¿è¡Œ
    wandb.finish()

# ==========================================================
# å¯åŠ¨å…¥å£
# ==========================================================
if __name__ == "__main__":
    main_train()