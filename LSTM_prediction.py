#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ„ç‰ˆ LSTM å¤šè¾“å…¥é¢„æµ‹è„šæœ¬ï¼ˆå« Wordle grid ç‰¹å¾ï¼ŒWandB-safe æ—¥å¿—ï¼‰
ç›´æ¥è¿è¡Œå³å¼€å§‹è®­ç»ƒï¼ˆé»˜è®¤ RUN_MODE="train"ï¼‰ã€‚
ä¿®æ­£ï¼šå°† parse_grid_column ä¸­çš„å¡«å……é€»è¾‘æ”¹ä¸ºä½¿ç”¨ç©ºè¡Œï¼Œé¿å…æœªæ¥ä¿¡æ¯æ³„éœ²ã€‚

æ–°å¢ï¼šå°†ç©å®¶çŒœè¯è¿‡ç¨‹ç¼–ç ä¸ºæ—¶é—´åºåˆ— (parse_grid_sequence)ã€‚
"""

import os
import json
import random
import ast
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import wandb
from typing import Dict, Tuple, List
from tensorflow.keras.layers import (Input, Dense, Dropout, Embedding, Flatten,
                                     LSTM, Bidirectional, Concatenate)
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, Callback
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, roc_auc_score, roc_curve

# ==========================================================
# å…¨å±€é…ç½®
# ==========================================================

TRAIN_FILE = "dataset/train_data.csv"
VAL_FILE = "dataset/val_data.csv"
TEST_FILE = "dataset/test_data.csv"

DIFFICULTY_FILE = "dataset/difficulty.csv"
PLAYER_FILE = "dataset/player_data.csv"

LOOK_BACK = 5
BATCH_SIZE = 1024
EPOCHS = 15
LEARNING_RATE = 0.0007

MODEL_SAVE_PATH = "models/lstm/lstm_model.keras"
TOKENIZER_PATH = "models/lstm/lstm_tokenizer.json"

# LSTM æ¶æ„å‚æ•°
LSTM_UNITS = 64
DROPOUT_RATE = 0.3
EMBEDDING_DIM = 32

OOV_TOKEN = "<OOV>"

LARGE_ERROR_THRESHOLD = 1.5
PATIENCE = 4
REPORT_SAVE_PATH = "outputs/lstm_output.txt"

# å›ºå®šéšæœºç§å­
SEED = 2009

# Wordleå›ºå®šå‚æ•°
MAX_TRIES = 6
GRID_FEAT_LEN = 8
# æ–°å¢: åºåˆ—ç‰¹å¾é•¿åº¦ (æ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾æ•°é‡)
GRID_SEQ_FEAT_DIM = 4 # ç»¿è‰²ã€é»„è‰²ã€ç°è‰²è®¡æ•° + å°è¯•æ¬¡æ•°å½’ä¸€åŒ–

def set_seed(seed):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    # è®¾ç½®ç¡®å®šæ€§æ“ä½œï¼ˆå¯èƒ½å¯¹æŸäº› TF ç‰ˆæœ¬æœ‰å½±å“ï¼‰
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

def ensure_dirs():
    os.makedirs(os.path.dirname(MODEL_SAVE_PATH) or ".", exist_ok=True)
    os.makedirs("outputs", exist_ok=True)
    os.makedirs("models/lstm", exist_ok=True)
    os.makedirs("visualization", exist_ok=True)

def safe_read_csv(path, usecols=None):
    if not os.path.exists(path):
        raise FileNotFoundError(f"File missing: {path}")
    return pd.read_csv(path, usecols=usecols)

# --------------------------
# Wordle grid parsing helper
# --------------------------
def parse_grid_column(grid_cell):
    """
    æœŸæœ› grid_cell ç±»ä¼¼ "['â¬œâ¬œâ¬œâ¬œâ¬œ','â¬œâ¬œâ¬œğŸŸ¨â¬œ',...]" æˆ–å·²ç»æ˜¯ listã€‚
    è¿”å›é•¿åº¦ä¸º GRID_FEAT_LEN çš„æµ®ç‚¹å‘é‡ï¼ˆç»Ÿè®¡ç‰¹å¾ï¼‰ã€‚
    è‹¥æ— æ³•è§£æï¼Œè¿”å›å…¨ 0 å‘é‡ã€‚
    """
    if pd.isna(grid_cell):
        return np.zeros(GRID_FEAT_LEN, dtype=np.float32)

    # è§£æç½‘æ ¼åˆ—è¡¨
    if isinstance(grid_cell, (list, tuple)):
        grid_list = list(grid_cell)
    else:
        try:
            grid_list = ast.literal_eval(grid_cell)
            if not isinstance(grid_list, (list, tuple)):
                grid_list = [grid_list]
            grid_list = [str(r) for r in grid_list if isinstance(r, (str, bytes))]
        except Exception:
            return np.zeros(GRID_FEAT_LEN, dtype=np.float32)

    num_rows = len(grid_list)

    # 1. Padding é€»è¾‘: ä¿®æ­£äº†ä½¿ç”¨æœ€åä¸€è¡Œå¡«å……çš„é—®é¢˜
    if num_rows < MAX_TRIES:
        # ç”¨ç©ºè¡Œ "â¬œâ¬œâ¬œâ¬œâ¬œ" å¡«å……æœªè¿›è¡Œçš„å°è¯•ï¼Œè€Œä¸æ˜¯ç”¨æœ€åä¸€è¡Œé‡å¤å¡«å……ï¼Œé¿å…æœªæ¥ä¿¡æ¯æ³„éœ²ã€‚
        blank_row = "â¬œâ¬œâ¬œâ¬œâ¬œ" 
        padding_rows = [blank_row] * (MAX_TRIES - num_rows)
        padded_grid_list = grid_list + padding_rows
    elif num_rows > MAX_TRIES:
        # å¦‚æœè¶…è¿‡ MAX_TRIESï¼Œåˆ™æˆªæ–­ï¼Œåªå–å‰ MAX_TRIES è¡Œï¼ˆé€šå¸¸ä¸åº”è¯¥å‘ç”Ÿï¼‰
        padded_grid_list = grid_list[:MAX_TRIES]
    else:
        # æ°å¥½ MAX_TRIES è¡Œæˆ– 0 è¡Œ
        padded_grid_list = grid_list

    # 2. ç»Ÿè®¡ç‰¹å¾ (åŸºäº Padding åçš„ 6 è¡Œ)
    greens = 0
    yellows = 0
    grays = 0
    pos_green_counts = np.zeros(5, dtype=np.float32)
    
    # å½’ä¸€åŒ–åŸºæ•°
    norm_base_cells = float(MAX_TRIES * 5)  # 6 * 5 = 30
    norm_base_rows = float(MAX_TRIES)      # 6
    
    # éå† Padding åçš„ç½‘æ ¼
    for row in padded_grid_list:
        if not isinstance(row, str) or len(row) != 5:
            continue
        for i, ch in enumerate(row):
            if ch == "ğŸŸ©":
                greens += 1
                if i < 5:
                    pos_green_counts[i] += 1.0
            elif ch == "ğŸŸ¨":
                yellows += 1
            elif ch == "â¬œ" or ch == "â¬›":
                grays += 1

    # 3. æ„å»ºç‰¹å¾å‘é‡
    feat = np.zeros(GRID_FEAT_LEN, dtype=np.float32)
    feat[0] = greens / norm_base_cells
    feat[1] = yellows / norm_base_cells
    feat[2] = grays / norm_base_cells
    
    # ä½ç½®ç»¿å æ¯”ï¼šé™¤ä»¥ MAX_TRIES (6)
    for i in range(5):
        feat[3 + i] = (pos_green_counts[i] / norm_base_rows)
        
    return feat


def parse_grid_sequence(grid_cell):
    """
    æ–°å¢å‡½æ•°ï¼šå°† grid åˆ—è¡¨è½¬æ¢ä¸ºä¸€ä¸ªæ—¶é—´åºåˆ—ç‰¹å¾çŸ©é˜µã€‚
    è¿”å›å½¢çŠ¶ä¸º (MAX_TRIES, GRID_SEQ_FEAT_DIM) çš„æµ®ç‚¹çŸ©é˜µã€‚
    æ—¶é—´æ­¥ i å¯¹åº”ç¬¬ i æ¬¡å°è¯•çš„ç»“æœã€‚
    """
    if pd.isna(grid_cell):
        # æ— æ³•è§£ææ—¶è¿”å›å…¨é›¶åºåˆ—
        return np.zeros((MAX_TRIES, GRID_SEQ_FEAT_DIM), dtype=np.float32)

    # è§£æç½‘æ ¼åˆ—è¡¨
    if isinstance(grid_cell, (list, tuple)):
        grid_list = list(grid_cell)
    else:
        try:
            grid_list = ast.literal_eval(grid_cell)
            if not isinstance(grid_list, (list, tuple)):
                grid_list = [grid_list]
            grid_list = [str(r) for r in grid_list if isinstance(r, (str, bytes))]
        except Exception:
            return np.zeros((MAX_TRIES, GRID_SEQ_FEAT_DIM), dtype=np.float32)

    num_rows = len(grid_list)
    seq_features = []
    
    # 1. åºåˆ—ç‰¹å¾æå–
    for t in range(MAX_TRIES):
        feat = np.zeros(GRID_SEQ_FEAT_DIM, dtype=np.float32)
        greens = 0
        yellows = 0
        grays = 0
        
        # å¦‚æœæ˜¯æœ‰æ•ˆçš„å°è¯•
        if t < num_rows:
            row = grid_list[t]
            if isinstance(row, str) and len(row) == 5:
                for ch in row:
                    if ch == "ğŸŸ©":
                        greens += 1
                    elif ch == "ğŸŸ¨":
                        yellows += 1
                    elif ch == "â¬œ" or ch == "â¬›":
                        grays += 1
            
            # ç‰¹å¾ 0-2: é¢œè‰²æ•°é‡å½’ä¸€åŒ– (é™¤ä»¥ 5)
            feat[0] = greens / 5.0
            feat[1] = yellows / 5.0
            feat[2] = grays / 5.0
            # ç‰¹å¾ 3: å°è¯•æ¬¡æ•°å½’ä¸€åŒ– (é™¤ä»¥ 6)
            feat[3] = (t + 1) / float(MAX_TRIES) 
        
        # å¦‚æœæ˜¯æœªè¿›è¡Œçš„å°è¯• (padding)ï¼Œåˆ™ç‰¹å¾å‘é‡ä¸ºå…¨ 0ï¼Œè¡¨ç¤ºç¼ºå¤±ä¿¡æ¯
        
        seq_features.append(feat)

    return np.array(seq_features, dtype=np.float32)


# --------------------------
# Tokenizer
# --------------------------
def fit_tokenizer(train_df):
    tokenizer = Tokenizer(oov_token=OOV_TOKEN, filters='', lower=True)
    tokenizer.fit_on_texts(train_df["target"].astype(str))
    with open(TOKENIZER_PATH, "w", encoding="utf-8") as f:
        json.dump(tokenizer.word_index, f, indent=2)
    return tokenizer

def load_tokenizer():
    with open(TOKENIZER_PATH, "r", encoding="utf-8") as f:
        word_index = json.load(f)
    tk = Tokenizer(oov_token=OOV_TOKEN)
    tk.word_index = word_index
    return tk

# --------------------------
# ç‰¹å¾é™„åŠ ï¼ˆåŒ…å« grid ç»Ÿè®¡å’Œåºåˆ—ï¼‰
# --------------------------
def attach_features(df, tokenizer, diff_map, user_map):
    df = df.copy()
    df["target"] = df["target"].astype(str)
    # å•è¯ idï¼ˆåªå–ç¬¬ä¸€ä¸ª token id æˆ– 0ï¼‰
    seqs = tokenizer.texts_to_sequences(df["target"])
    df["word_id"] = [s[0] if s else 0 for s in seqs]
    df["word_difficulty"] = df["target"].map(diff_map).fillna(4.0).astype(float)
    df["user_bias"] = df["Username"].map(user_map).fillna(4.0).astype(float)

    # è§£æ grid åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if "processed_text" in df.columns:
        df["grid_feat"] = df["processed_text"].apply(parse_grid_column)
        # æ–°å¢: è§£æ grid åºåˆ—
        df["grid_seq"] = df["processed_text"].apply(parse_grid_sequence)
    else:
        df["grid_feat"] = [np.zeros(GRID_FEAT_LEN, dtype=np.float32) for _ in range(len(df))]
        # æ–°å¢: ç¼ºå¤±æ—¶è¿”å›é›¶åºåˆ—
        df["grid_seq"] = [np.zeros((MAX_TRIES, GRID_SEQ_FEAT_DIM), dtype=np.float32) for _ in range(len(df))]

    return df

# --------------------------
# å†å²å»ºè¡¨ï¼ˆæ¯æ¡è®°å½•å­˜å…¥ grid_feat å’Œ grid_seqï¼‰
# --------------------------
def build_history(df) -> Dict[str, List[Tuple]]:
    hist = {}
    df_sorted = df.sort_values(["Username", "Game"])
    for u, g in df_sorted.groupby("Username", sort=False):
        hist[u] = [(int(r["Trial"]),
                    float(r["word_difficulty"]),
                    int(r["word_id"]),
                    float(r["user_bias"]),
                    np.array(r["grid_feat"], dtype=np.float32),  # ç´¢å¼• 4: ç»Ÿè®¡ç‰¹å¾
                    np.array(r["grid_seq"], dtype=np.float32))   # ç´¢å¼• 5: åºåˆ—ç‰¹å¾
                   for _, r in g.iterrows()]
    return hist

# --------------------------
# æ»‘çª—ç”Ÿæˆæ ·æœ¬ï¼ˆåŒ…å« grid ç»Ÿè®¡ç‰¹å¾å’Œåºåˆ—ç‰¹å¾ï¼‰
# --------------------------
def create_samples(history, look_back):
    # X_grid æ˜¯ç»Ÿè®¡ç‰¹å¾, X_grid_seq æ˜¯åºåˆ—ç‰¹å¾
    X_seq, X_diff, X_wid, X_bias, X_grid, X_grid_seq, y_steps, y_succ = [], [], [], [], [], [], [], []
    for _, events in history.items():
        if len(events) <= look_back:
            continue
        for i in range(look_back, len(events)):
            window = events[i-look_back:i]
            target = events[i]

            trials = np.array([t[0] for t in window], np.float32)
            norm = trials / 7.0
            std = np.std(trials) / 7.0

            seq = np.stack([norm, np.full_like(norm, std)], axis=1)
            X_seq.append(seq)
            X_diff.append([target[1] / 7.0])
            X_wid.append([target[2]])
            X_bias.append([target[3] / 7.0])
            X_grid.append(target[4])      # ç»Ÿè®¡ç‰¹å¾
            X_grid_seq.append(target[5])  # åºåˆ—ç‰¹å¾

            y_steps.append(min(float(target[0]), 7.0))
            y_succ.append(1.0 if target[0] <= 6 else 0.0)

    if not X_seq:
        return (np.zeros((0, look_back, 2), np.float32),
                np.zeros((0, 1), np.float32),
                np.zeros((0, 1), np.int32),
                np.zeros((0, 1), np.float32),
                np.zeros((0, GRID_FEAT_LEN), np.float32),
                np.zeros((0, MAX_TRIES, GRID_SEQ_FEAT_DIM), np.float32), # æ–°å¢ï¼šåºåˆ—ç‰¹å¾å½¢çŠ¶
                np.zeros((0,), np.float32),
                np.zeros((0,), np.float32))

    return (
        np.array(X_seq, np.float32),
        np.array(X_diff, np.float32),
        np.array(X_wid, np.int32),
        np.array(X_bias, np.float32),
        np.array(X_grid, np.float32),
        np.array(X_grid_seq, np.float32), # æ–°å¢ï¼šåºåˆ—ç‰¹å¾æ•°ç»„
        np.array(y_steps, np.float32),
        np.array(y_succ, np.float32)
    )

# ==========================================================
# LSTM æ¨¡å‹ï¼ˆåŠ å…¥ grid åºåˆ—æ”¯æŒï¼‰
# ==========================================================
def build_model(look_back, vocab_size):
    # å†å²è¾“å…¥åˆ†æ”¯ (ç©å®¶å†å²æˆç»©åºåˆ—)
    h_in = Input((look_back, 2), name="input_history")
    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(h_in)
    x = Dropout(DROPOUT_RATE)(x)
    x = Bidirectional(LSTM(LSTM_UNITS // 2))(x)
    x = Dropout(DROPOUT_RATE)(x)

    # éš¾åº¦è¾“å…¥åˆ†æ”¯
    diff_in = Input((1,), name="input_difficulty")
    d1 = Dense(16, activation="relu")(diff_in)

    # å•è¯IDè¾“å…¥åˆ†æ”¯
    wid_in = Input((1,), name="input_word_id", dtype="int32")
    wemb = Flatten()(Embedding(vocab_size, EMBEDDING_DIM)(wid_in))

    # ç”¨æˆ·åç½®è¾“å…¥åˆ†æ”¯
    bias_in = Input((1,), name="input_user_bias")
    b1 = Dense(16, activation="relu")(bias_in)

    # Wordle grid ç»Ÿè®¡è¾“å…¥åˆ†æ”¯
    grid_in = Input((GRID_FEAT_LEN,), name="input_grid_stat") # æ”¹åä»¥åŒºåˆ†
    g1 = Dense(16, activation="relu")(grid_in)
    
    # æ–°å¢: Wordle grid åºåˆ—è¾“å…¥åˆ†æ”¯
    grid_seq_in = Input((MAX_TRIES, GRID_SEQ_FEAT_DIM), name="input_grid_sequence")
    g_seq = Bidirectional(LSTM(LSTM_UNITS // 4))(grid_seq_in)
    g_seq = Dropout(DROPOUT_RATE)(g_seq)
    g2 = Dense(16, activation="relu")(g_seq) # é™ç»´

    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    # æ³¨æ„: å¢åŠ äº† g2 (grid_seq_in çš„è¾“å‡º)
    z = Concatenate()([x, d1, wemb, b1, g1, g2]) 
    z = Dense(64, activation="relu")(z)
    z = Dropout(DROPOUT_RATE)(z)

    # è¾“å‡ºå±‚
    out_steps = Dense(1, "linear", name="output_steps")(Dense(32, "relu")(z))
    out_succ = Dense(1, "sigmoid", name="output_success")(Dense(16, "relu")(z))

    # æ›´æ–°æ¨¡å‹è¾“å…¥åˆ—è¡¨
    model = Model([h_in, diff_in, wid_in, bias_in, grid_in, grid_seq_in], [out_steps, out_succ])
    model.compile(
        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),
        loss={"output_steps": "mse",
              "output_success": "binary_crossentropy"},
        loss_weights={"output_steps": 1.0, "output_success": 0.5},
        metrics={"output_success": "accuracy"}
    )
    return model

# ==========================================================
# è¯„ä¼°å‡½æ•°
# ==========================================================
def evaluate_model(model, Xs):
    # Xs ç´¢å¼•æ›´æ–°: X_grid_seq ä¸ºç´¢å¼• 5
    X_seq, X_diff, X_wid, X_bias, X_grid, X_grid_seq, y_steps, y_succ = Xs
    pred_steps, pred_prob = model.predict({
        "input_history": X_seq,
        "input_difficulty": X_diff,
        "input_word_id": X_wid,
        "input_user_bias": X_bias,
        "input_grid_stat": X_grid, # æ›´æ–°é”®å
        "input_grid_sequence": X_grid_seq # æ–°å¢è¾“å…¥
    }, batch_size=1024, verbose=1)
    pred_steps = pred_steps.flatten()
    pred_prob = pred_prob.flatten()

    mae = mean_absolute_error(y_steps, np.clip(pred_steps, 0, 7))
    rmse = np.sqrt(mean_squared_error(y_steps, np.clip(pred_steps, 0, 7)))
    acc = accuracy_score(y_succ.astype(int), (pred_prob >= 0.5).astype(int))
    try:
        auc = roc_auc_score(y_succ, pred_prob)
    except:
        auc = float("nan")

    print(f"MAE={mae:.4f}, RMSE={rmse:.4f}, ACC={acc:.4f}, AUC={auc}")
    return mae, rmse, acc, auc

def compute_large_error_rate(y_true, y_pred, threshold):
    errors = np.abs(y_true - y_pred)
    return np.mean(errors > threshold)

def plot_roc_curve(y_true, y_pred, save_path):
    fpr, tpr, _ = roc_curve(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc_score(y_true, y_pred):.3f})')
    plt.plot([0, 1], [0, 1], linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.grid(True, alpha=0.3)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"AUC curve saved to: {save_path}")

def plot_loss(history, save_path):
    plt.figure(figsize=(12, 6))
    # Plot total loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    if 'val_loss' in history.history:
        plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Plot component losses
    plt.subplot(1, 2, 2)
    if 'output_steps_loss' in history.history:
        plt.plot(history.history['output_steps_loss'], label='Training Steps Loss')
        if 'val_output_steps_loss' in history.history:
            plt.plot(history.history['val_output_steps_loss'], label='Validation Steps Loss')
    if 'output_success_loss' in history.history:
        plt.plot(history.history['output_success_loss'], label='Training Success Loss')
        if 'val_output_success_loss' in history.history:
            plt.plot(history.history['val_output_success_loss'], label='Validation Success Loss')
    plt.title('Component Losses')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Loss curve saved to: {save_path}")

# ==========================================================
# WandB-safe Keras Callbackï¼ˆåªè®°å½• epoch æŒ‡æ ‡ï¼Œä¸è§¦å‘ graph é‡‡æ ·ï¼‰
# ==========================================================
class WandbEpochLogger(Callback):
    def __init__(self):
        super().__init__()

    def on_epoch_end(self, epoch, logs=None):
        if logs is None:
            logs = {}
        # å°†æ‰€æœ‰å¯è®°å½•çš„æŒ‡æ ‡å†™å…¥ wandbï¼ˆå¸¦ stepï¼‰
        # ä½¿ç”¨ epoch ä½œä¸º step
        metrics = {k: float(v) for k, v in logs.items()}
        metrics["epoch"] = int(epoch)
        wandb.log(metrics, step=epoch)

# ==========================================================
# ä¸»ç¨‹åº
# ==========================================================
def main_train():
    set_seed(SEED)
    ensure_dirs()

    # WandB åˆå§‹åŒ–
    wandb.init(
        project="word-difficulty-prediction",
        name="lstm-model-grid-seq-run",
        config={
            "model_type": "LSTM_Grid_Seq",
            "look_back": LOOK_BACK,
            "batch_size": BATCH_SIZE,
            "epochs": EPOCHS,
            "learning_rate": LEARNING_RATE,
            "lstm_units": LSTM_UNITS,
            "dropout_rate": DROPOUT_RATE,
            "embedding_dim": EMBEDDING_DIM,
            "seed": SEED,
            "grid_feat_len": GRID_FEAT_LEN,
            "grid_seq_feat_dim": GRID_SEQ_FEAT_DIM # æ–°å¢é…ç½®
        },
        settings=wandb.Settings(_disable_stats=True)  # å…³é—­æŸäº›è‡ªåŠ¨ç»Ÿè®¡ï¼Œé¿å… graph å†™å…¥
    )

    # å°è¯•ç§»é™¤å¯èƒ½æ®‹ç•™çš„ graph å­—æ®µï¼ˆé˜²å¾¡æ€§ï¼‰
    try:
        if hasattr(wandb.run, "summary") and "graph" in wandb.run.summary:
            wandb.run.summary.pop("graph", None)
    except Exception:
        pass

    # 1. æ•°æ®è¯»å–
    use_cols_list = ["Game", "Trial", "Username", "target", "processed_text"]
    train_df = safe_read_csv(TRAIN_FILE, usecols=use_cols_list)
    val_df = safe_read_csv(VAL_FILE, usecols=use_cols_list)
    test_df = safe_read_csv(TEST_FILE, usecols=use_cols_list)

    # 2. éš¾åº¦/ç”¨æˆ·æ°´å¹³
    diff_map = {}
    user_map = {}
    if os.path.exists(DIFFICULTY_FILE):
        ddf = pd.read_csv(DIFFICULTY_FILE)
        diff_map = dict(zip(ddf["word"], ddf["avg_trial"]))
    if os.path.exists(PLAYER_FILE):
        pdf = pd.read_csv(PLAYER_FILE)
        user_map = dict(zip(pdf["Username"], pdf["avg_trial"]))

    # 3. Tokenizerï¼ˆtrain-onlyï¼‰
    tokenizer = fit_tokenizer(train_df)

    # 4. é™„åŠ ç‰¹å¾ï¼ˆå« grid ç»Ÿè®¡å’Œåºåˆ—ï¼‰
    train_df = attach_features(train_df, tokenizer, diff_map, user_map)
    val_df = attach_features(val_df, tokenizer, diff_map, user_map)
    test_df = attach_features(test_df, tokenizer, diff_map, user_map)

    # 5. Build histories
    hist_train = build_history(train_df)
    hist_val = build_history(val_df)
    hist_test = build_history(test_df)

    # 6. Sliding samplesï¼ˆåŒ…å« grid ç»Ÿè®¡å’Œåºåˆ—ï¼‰
    # X_set ç»“æ„ï¼š(seq, diff, wid, bias, grid_stat, grid_seq, y_steps, y_succ)
    X_train = create_samples(hist_train, LOOK_BACK)
    X_val = create_samples(hist_val, LOOK_BACK)
    X_test = create_samples(hist_test, LOOK_BACK)

    print(f"Train={len(X_train[0])}, Val={len(X_val[0])}, Test={len(X_test[0])}")

    vocab_size = len(tokenizer.word_index) + 1

    # 7. Model
    model = build_model(LOOK_BACK, vocab_size)
    model.summary()

    # 8. TF dataset
    train_ds = tf.data.Dataset.from_tensor_slices((
        {
            "input_history": X_train[0],
            "input_difficulty": X_train[1],
            "input_word_id": X_train[2],
            "input_user_bias": X_train[3],
            "input_grid_stat": X_train[4],      # ç»Ÿè®¡ç‰¹å¾
            "input_grid_sequence": X_train[5]   # åºåˆ—ç‰¹å¾
        },
        {
            "output_steps": X_train[6],
            "output_success": X_train[7]
        }
    )).shuffle(20000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    val_ds = tf.data.Dataset.from_tensor_slices((
        {
            "input_history": X_val[0],
            "input_difficulty": X_val[1],
            "input_word_id": X_val[2],
            "input_user_bias": X_val[3],
            "input_grid_stat": X_val[4],
            "input_grid_sequence": X_val[5]
        },
        {
            "output_steps": X_val[6],
            "output_success": X_val[7]
        }
    )).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # 9. è®­ç»ƒ
    early = EarlyStopping(monitor="val_loss", patience=PATIENCE, restore_best_weights=True)
    wandb_logger = WandbEpochLogger()

    train_history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=[early, wandb_logger]
    )

    # ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±æ›²çº¿
    loss_curve_path = "visualization/LSTM_loss_curve.png"
    plot_loss(train_history, loss_curve_path)

    # å°†æŸå¤±æ›²çº¿ä¸Šä¼ åˆ°WandB
    try:
        wandb.log({"loss_curve": wandb.Image(loss_curve_path)})
    except Exception:
        pass

    model.save(MODEL_SAVE_PATH)
    print(f"Model saved to {MODEL_SAVE_PATH}")

    # éªŒè¯è¯„ä¼°
    print("\n=== Validation ===")
    val_mae, val_rmse, val_acc, val_auc = evaluate_model(model, X_val)

    # è®°å½•éªŒè¯é›†æŒ‡æ ‡åˆ°wandb
    wandb.log({
        "val_mae": val_mae,
        "val_rmse": val_rmse,
        "val_accuracy": val_acc,
        "val_auc": val_auc
    })

    # ç»˜åˆ¶éªŒè¯é›†AUCæ›²çº¿ (ä½¿ç”¨æ›´æ–°åçš„ç´¢å¼• 7: y_succ)
    val_pred_steps, val_pred_prob = model.predict({
        "input_history": X_val[0],
        "input_difficulty": X_val[1],
        "input_word_id": X_val[2],
        "input_user_bias": X_val[3],
        "input_grid_stat": X_val[4],
        "input_grid_sequence": X_val[5]
    }, batch_size=1024, verbose=0)
    val_roc_curve_path = "visualization/LSTM_validation_roc_curve.png"
    plot_roc_curve(X_val[7], val_pred_prob.flatten(), val_roc_curve_path)
    try:
        wandb.log({"validation_roc_curve": wandb.Image(val_roc_curve_path)})
    except Exception:
        pass

    # æµ‹è¯•è¯„ä¼°
    print("\n=== Test ===")
    test_mae, test_rmse, test_acc, test_auc = evaluate_model(model, X_test)

    wandb.log({
        "test_mae": test_mae,
        "test_rmse": test_rmse,
        "test_accuracy": test_acc,
        "test_auc": test_auc
    })

    # ç»˜åˆ¶æµ‹è¯•é›†AUCæ›²çº¿ (ä½¿ç”¨æ›´æ–°åçš„ç´¢å¼• 7: y_succ)
    test_pred_steps, test_pred_prob = model.predict({
        "input_history": X_test[0],
        "input_difficulty": X_test[1],
        "input_word_id": X_test[2],
        "input_user_bias": X_test[3],
        "input_grid_stat": X_test[4],
        "input_grid_sequence": X_test[5]
    }, batch_size=1024, verbose=0)
    test_roc_curve_path = "visualization/LSTM_test_roc_curve.png"
    plot_roc_curve(X_test[7], test_pred_prob.flatten(), test_roc_curve_path)
    try:
        wandb.log({"test_roc_curve": wandb.Image(test_roc_curve_path)})
    except Exception:
        pass

    # --------------------------------------------------------
    # ç”Ÿæˆå¤§å‹è¯¯å·®ç»Ÿè®¡ (ä½¿ç”¨æ›´æ–°åçš„ç´¢å¼• 6: y_steps)
    # --------------------------------------------------------
    val_pred_steps, _ = model.predict({
        "input_history": X_val[0],
        "input_difficulty": X_val[1],
        "input_word_id": X_val[2],
        "input_user_bias": X_val[3],
        "input_grid_stat": X_val[4],
        "input_grid_sequence": X_val[5]
    }, batch_size=1024, verbose=0)
    val_pred_steps = val_pred_steps.flatten()
    val_large_error_rate = compute_large_error_rate(X_val[6], np.clip(val_pred_steps, 0, 7), LARGE_ERROR_THRESHOLD)

    test_pred_steps, _ = model.predict({
        "input_history": X_test[0],
        "input_difficulty": X_test[1],
        "input_word_id": X_test[2],
        "input_user_bias": X_test[3],
        "input_grid_stat": X_test[4],
        "input_grid_sequence": X_test[5]
    }, batch_size=1024, verbose=0)
    test_pred_steps = test_pred_steps.flatten()
    test_large_error_rate = compute_large_error_rate(X_test[6], np.clip(test_pred_steps, 0, 7), LARGE_ERROR_THRESHOLD)

    # --------------------------------------------------------
    # æ ¼å¼åŒ–æŠ¥å‘Š
    # --------------------------------------------------------
    report = f"""
========================================
 LSTM Model Validation and Test Report 
========================================
---- Validation Set Metrics ----
1. Mean Absolute Error (MAE)    : {val_mae:.4f}
2. Root Mean Squared Error (RMSE)     : {val_rmse:.4f}
3. Win/Loss Prediction Accuracy        : {val_acc:.3%}
4. Area Under ROC Curve (AUC)   : {val_auc:.4f}
5. Large Error Rate (>{LARGE_ERROR_THRESHOLD} steps)  : {val_large_error_rate:.3%}

---- Test Set Metrics ----
1. Mean Absolute Error (MAE)    : {test_mae:.4f}
2. Root Mean Squared Error (RMSE)     : {test_rmse:.4f}
3. Win/Loss Prediction Accuracy        : {test_acc:.3%}
4. Area Under ROC Curve (AUC)   : {test_auc:.4f}
5. Large Error Rate (>{LARGE_ERROR_THRESHOLD} steps)  : {test_large_error_rate:.3%}
========================================
"""

    with open(REPORT_SAVE_PATH, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nğŸ“„ Report saved to: {REPORT_SAVE_PATH}")
    print(report)

    wandb.log({
        "val_large_error_rate": val_large_error_rate,
        "test_large_error_rate": test_large_error_rate
    })

    # ç»“æŸ wandb è¿è¡Œ
    wandb.finish()

# é¢„æµ‹æ¨¡å¼ï¼ˆæŒ‰éœ€å¯ç”¨ï¼‰
def main_predict(user_id):
    if not os.path.exists(MODEL_SAVE_PATH):
        raise FileNotFoundError("è¯·å…ˆè®­ç»ƒæ¨¡å‹ã€‚")

    model = tf.keras.models.load_model(MODEL_SAVE_PATH)
    tokenizer = load_tokenizer()

    df = safe_read_csv(TRAIN_FILE, usecols=["Game", "Trial", "Username", "target", "processed_text"])
    diff_map = {}
    user_map = {}
    if os.path.exists(DIFFICULTY_FILE):
        ddf = pd.read_csv(DIFFICULTY_FILE)
        diff_map = dict(zip(ddf["word"], ddf["avg_trial"]))
    if os.path.exists(PLAYER_FILE):
        pdf = pd.read_csv(PLAYER_FILE)
        user_map = dict(zip(pdf["Username"], pdf["avg_trial"]))

    df = attach_features(df, tokenizer, diff_map, user_map)
    hist = build_history(df)

    if user_id not in hist:
        print(f"ç”¨æˆ· {user_id} æ— è®°å½•")
        return

    events = hist[user_id]
    if len(events) < 1:
        print("å†å²ä¸è¶³")
        return

    # å‡†å¤‡è¾“å…¥
    if len(events) < LOOK_BACK:
        avg = np.mean([e[0] for e in events])
        # å¡«å…… tuple é•¿åº¦éœ€è¦åŒ¹é… build_history ä¸­çš„ 6 ä¸ªå…ƒç´ 
        pad_event = (avg, 4.0, 0, 4.0, np.zeros(GRID_FEAT_LEN, dtype=np.float32), 
                     np.zeros((MAX_TRIES, GRID_SEQ_FEAT_DIM), dtype=np.float32))
        pad = [pad_event] * (LOOK_BACK - len(events))
        window = pad + events
    else:
        window = events[-LOOK_BACK:]

    trials = np.array([w[0] for w in window], np.float32)
    seq = np.stack([trials/7.0, np.full_like(trials, np.std(trials)/7.0)], axis=1)
    seq = seq.reshape(1, LOOK_BACK, 2)

    last = events[-1]
    diff = np.array([[last[1] / 7.0]], np.float32)
    wid = np.array([[last[2]]], np.int32)
    bias = np.array([[last[3] / 7.0]], np.float32)
    grid_stat = last[4].reshape(1, GRID_FEAT_LEN) # ç»Ÿè®¡ç‰¹å¾ (ç´¢å¼• 4)
    grid_seq = last[5].reshape(1, MAX_TRIES, GRID_SEQ_FEAT_DIM) # åºåˆ—ç‰¹å¾ (ç´¢å¼• 5)

    p_steps, p_prob = model.predict({
        "input_history": seq,
        "input_difficulty": diff,
        "input_word_id": wid,
        "input_user_bias": bias,
        "input_grid_stat": grid_stat,
        "input_grid_sequence": grid_seq
    }, verbose=0)

    print(f"é¢„æµ‹æ­¥æ•°: {float(np.clip(p_steps, 0, 6.99)):.2f}")
    print(f"æˆåŠŸæ¦‚ç‡: {float(p_prob):.3f}")

# ==========================================================
# å¯åŠ¨å…¥å£
# ==========================================================
if __name__ == "__main__":
    main_train()
    
# < 