import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import LSTM, Dense, Input, Dropout, Embedding, Flatten, Concatenate
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, roc_auc_score, confusion_matrix, precision_recall_fscore_support
from sklearn.model_selection import train_test_split
from tensorflow.keras.mixed_precision import set_global_policy
from tensorflow.keras.callbacks import EarlyStopping
import random
import os
import io
import wandb
from wandb.keras import WandbCallback
import matplotlib.pyplot as plt

# WandBå…¨å±€æ§åˆ¶å˜é‡
WANDB_ENABLED = True  # æ§åˆ¶æ˜¯å¦å¯ç”¨WandB
wandb_run = None  # å­˜å‚¨wandb runå®ä¾‹
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# ==========================================
# 0. ç”¨æˆ·é…ç½®å‚æ•° (STRICT CONFIG)
# ==========================================
# æ•°æ®é…ç½®
FILE_PATH = 'dataset/cleaned_dataset.csv'
MAX_ROWS = 6923127
LOOK_BACK = 8       # å†å²çª—å£å¤§å°

# æ¨¡å‹ç»“æ„é…ç½®
LSTM_UNITS = 32      # LSTMéšè—å•å…ƒæ•°
LSTM_LAYERS = 2      # LSTMå±‚æ•°
DROPOUT_RATE = 0.3   # Dropoutæ¯”ç‡
EMBEDDING_DIM = 32   # è¯åµŒå…¥ç»´åº¦

# è®­ç»ƒé…ç½®
EPOCHS = 10         
BATCH_SIZE = 2048    
LEARNING_RATE = 0.001 # å­¦ä¹ ç‡
PATIENCE = 4         # æ—©åœè€å¿ƒå€¼

# è¯„ä¼°é…ç½®
LARGE_ERROR_THRESHOLD = 2.0  # ä¿®æ”¹ä¸ºåå·®2æ­¥

# å…¶ä»–é…ç½®
MODEL_SAVE_PATH = 'LSTM_Model'

# WandB é…ç½®
WANDB_PROJECT = 'wordle-prediction'
WANDB_RUN_NAME = 'lstm-experiment'

# ==========================================
# 1. æ•°æ®åŠ è½½ä¸é«˜çº§ç‰¹å¾å·¥ç¨‹
# ==========================================

def process_data_and_extract_features(file_path, nrows):
    """è¯»å–æ•°æ®ï¼Œè®¡ç®—å•è¯éš¾åº¦ã€å•è¯IDã€ç”¨æˆ·å¹³å‡åå¥½ã€‚"""
    print("Step 1: è¯»å–æ•°æ®å¹¶æ„å»ºå››ç‰¹å¾...")
    try:
        df = pd.read_csv(file_path, nrows=nrows, usecols=['Game', 'Trial', 'Username', 'target'])
        df = df.dropna()
    except:
        # æ¨¡æ‹Ÿæ•°æ®... (çœç•¥æ¨¡æ‹Ÿé€»è¾‘ï¼Œè§å‰ä¸€ä¸ªç‰ˆæœ¬)
        print("âš ï¸ æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿ wordle_games.csv å­˜åœ¨ã€‚")
        return {}, 2, None, None 

    # --- Feature A & B: å•è¯éš¾åº¦ (Difficulty) & å•è¯ ID (Embedding) ---
    word_stats = df.groupby('target')['Trial'].mean().to_dict()
    df['word_difficulty'] = df['target'].map(word_stats)
    tokenizer = Tokenizer(); tokenizer.fit_on_texts(df['target'])
    df['word_id'] = df['target'].apply(lambda x: tokenizer.texts_to_sequences([x])[0][0])
    vocab_size = len(tokenizer.word_index) + 1

    # --- Feature C: ç”¨æˆ·åå¥½ (User Bias) ---
    # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„å…¨å±€å¹³å‡æ­¥æ•°
    user_stats = df.groupby('Username')['Trial'].mean().to_dict()
    df['user_bias'] = df['Username'].map(user_stats)

    df = df.sort_values(by=['Username', 'Game'])
    
    # æ„å»ºå¤åˆå­—å…¸ï¼š(Trial, Difficulty, WordID, UserBias)
    history_map = df.groupby('Username').apply(
        lambda x: list(zip(x['Trial'], x['word_difficulty'], x['word_id'], x['user_bias']))
    ).to_dict()
    
    return history_map, vocab_size, tokenizer, word_stats

def create_multi_input_dataset(user_history_map, look_back):
    """æ„å»ºå››è¾“å…¥æ•°æ®é›†ï¼šX_seq, X_diff, X_word, X_bias."""
    print("Step 2: æ„å»ºå››è¾“å…¥æ ·æœ¬...")
    
    X_seq_list = []
    X_diff_list = []; X_word_list = []; X_bias_list = []
    y_steps = []; y_success = []
    valid_players = []

    for user, history in user_history_map.items():
        if len(history) > look_back:
            for i in range(len(history) - look_back):
                
                # --- 1. å†å²åºåˆ—ç‰¹å¾ (LSTM Input) ---
                past_trials = [h[0] for h in history[i : i+look_back]]
                past_arr = np.array(past_trials)
                std_dev = np.std(past_arr) / 7.0; seq_norm = past_arr / 7.0
                seq_2d = np.stack([seq_norm, np.full_like(seq_norm, std_dev)], axis=1)
                
                # --- 2. ç›®æ ‡ä¿¡æ¯å’Œç”¨æˆ·åå¥½ (Context Inputs) ---
                target_game = history[i + look_back]
                target_trial = target_game[0]
                target_difficulty = target_game[1]
                target_word_id = target_game[2]
                target_user_bias = target_game[3] # æ–°å¢
                
                # æ”¶é›†æ•°æ®
                X_seq_list.append(seq_2d)
                X_diff_list.append(target_difficulty / 7.0) 
                X_word_list.append(target_word_id)
                X_bias_list.append(target_user_bias / 7.0) # æ–°å¢
                
                # æ ‡ç­¾ - ä¿®æ”¹ä¸ºåˆ†ç±»ä»»åŠ¡
                # ç¡®ä¿target_trialåœ¨1-7èŒƒå›´å†…
                trial_category = min(target_trial, 7)
                # åˆ›å»ºone-hotç¼–ç  (7ä¸ªç±»åˆ«ï¼Œå¯¹åº”1-7æ­¥)
                one_hot = np.zeros(7, dtype=np.float32)
                one_hot[trial_category - 1] = 1.0  # ç´¢å¼•ä»0å¼€å§‹ï¼Œæ­¥æ•°ä»1å¼€å§‹
                y_steps.append(one_hot)
                y_success.append(1.0 if target_trial <= 6 else 0.0)
            
            valid_players.append(user)

    return (
        np.array(X_seq_list, dtype=np.float32),
        np.array(X_diff_list, dtype=np.float32),
        np.array(X_word_list, dtype=np.float32),
        np.array(X_bias_list, dtype=np.float32), # æ–°å¢è¾“å‡º
        np.array(y_steps),  # one-hotç¼–ç å·²ä¸ºfloat32
        np.array(y_success, dtype=np.float32),
        valid_players
    )

# ==========================================
# 2. æ¨¡å‹æ„å»º (Multi-Input Four Branch)
# ==========================================

def build_context_model(look_back, vocab_size, embedding_dim):
    print(f"Step 3: æ„å»ºå››è¾“å…¥ç¥ç»ç½‘ç»œ (Vocab={vocab_size})...")
    
    # --- Input 1: ç©å®¶å†å² (LSTM) ---
    input_hist = Input(shape=(look_back, 2), name='input_history')
    
    # æ ¹æ®LSTM_LAYERSå‚æ•°åŠ¨æ€æ„å»ºå¤šå±‚LSTM
    x1 = input_hist
    for i in range(LSTM_LAYERS):
        return_sequences = (i < LSTM_LAYERS - 1)  # æœ€åä¸€å±‚ä¸è¿”å›åºåˆ—
        x1 = LSTM(LSTM_UNITS if i > 0 else 128, return_sequences=return_sequences)(x1)
        x1 = Dropout(DROPOUT_RATE)(x1)
    
    # --- Input 2: å•è¯éš¾åº¦ (Dense) ---
    input_diff = Input(shape=(1,), name='input_difficulty'); x2 = Dense(16, activation='relu')(input_diff)
    
    # --- Input 3: å•è¯ ID (Embedding) ---
    input_word = Input(shape=(1,), name='input_word_id'); x3 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1)(input_word); x3 = Flatten()(x3)
    
    # --- Input 4: ç”¨æˆ·åå¥½ (Dense) ---
    input_bias = Input(shape=(1,), name='input_user_bias'); x4 = Dense(16, activation='relu')(input_bias) # æ–°å¢
    
    # --- èåˆå±‚ (Concatenate) ---
    combined = Concatenate()([x1, x2, x3, x4]) # èåˆå››ä¸ªåˆ†æ”¯
    
    z = Dense(64, activation='relu')(combined); z = Dropout(0.2)(z)
    
    # --- è¾“å‡ºå±‚ ---
    # ä¿®æ”¹ä¸º7åˆ†ç±»ä»»åŠ¡ï¼ˆ1-7æ­¥ï¼‰ï¼Œä½¿ç”¨softmaxæ¿€æ´»å‡½æ•°
    out_steps = Dense(7, activation='softmax', name='output_steps', dtype='float32')(Dense(32, activation='relu')(z))
    out_success = Dense(1, activation='sigmoid', name='output_success', dtype='float32')(Dense(16, activation='relu')(z))
    
    # å¿…é¡»æ›´æ–° inputs åˆ—è¡¨
    model = Model(inputs=[input_hist, input_diff, input_word, input_bias], outputs=[out_steps, out_success])
    
    # ä½¿ç”¨æŒ‡å®šçš„å­¦ä¹ ç‡åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)
    
    model.compile(optimizer=optimizer,
                  loss={'output_steps': 'categorical_crossentropy', 'output_success': 'binary_crossentropy'},
                  loss_weights={'output_steps': 1.0, 'output_success': 0.5},
                  metrics={'output_steps': ['accuracy'], 'output_success': 'accuracy'})
    return model

# ==========================================
# 3. éªŒè¯ä¸å›æµ‹é€»è¾‘ (ä¿®æ­£åçš„ç‰ˆæœ¬)
# ==========================================

def prepare_single_inference_input(history_tuples, target_diff, target_word_id, target_user_bias, look_back):
    """è¾…åŠ©å‡½æ•°ï¼šä¸ºå•æ¬¡é¢„æµ‹å‡†å¤‡å››è¾“å…¥å¼ é‡ã€‚"""
    trials = [h[0] for h in history_tuples]
    arr = np.array(trials)
    
    # æ„é€  Input 1 (History)
    std = np.std(arr) / 7.0; norm = arr / 7.0
    seq_2d = np.stack([norm, np.full_like(norm, std)], axis=1).reshape(1, look_back, 2)
    # æ„é€  Input 2, 3, 4 (Context)
    diff_in = np.array([target_diff / 7.0]).reshape(1, 1)
    word_in = np.array([target_word_id]).reshape(1, 1)
    bias_in = np.array([target_user_bias / 7.0]).reshape(1, 1)
    
    return [
        seq_2d.astype(np.float32), 
        diff_in.astype(np.float32), 
        word_in.astype(np.float32), 
        bias_in.astype(np.float32)
    ]

def evaluate_model_and_get_preds(model, val_inputs, val_labels):
    """è¿›è¡Œæ‰¹é‡é¢„æµ‹ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œå¹¶è¿”å›é¢„æµ‹ç»“æœã€‚"""
    print("\nStep 4: å¼€å§‹æ‰¹é‡é¢„æµ‹ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡...")
    
    # æ‰¹é‡é¢„æµ‹ (verbose=1 å¼€å¯è¿›åº¦æ¡)
    predictions = model.predict(val_inputs, batch_size=BATCH_SIZE, verbose=1)
    
    # å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œpredictions[0]æ˜¯ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ
    pred_steps_probs = predictions[0]
    pred_success_prob = predictions[1].flatten()
    
    # ä»one-hotç¼–ç çš„çœŸå®æ ‡ç­¾ä¸­è·å–ç±»åˆ«ç´¢å¼• (1-7)
    true_steps_discrete = np.argmax(val_labels['output_steps'], axis=1) + 1  # +1å› ä¸ºç´¢å¼•ä»0å¼€å§‹ï¼Œæ­¥æ•°ä»1å¼€å§‹
    
    # è·å–é¢„æµ‹çš„ç±»åˆ« (1-7)
    pred_steps_discrete = np.argmax(pred_steps_probs, axis=1) + 1
    
    return pred_steps_probs, pred_steps_discrete, true_steps_discrete, pred_success_prob

def perform_validation(model, user_history_map, valid_players, look_back, sample_size, threshold, pred_steps_full):
    print("ğŸ” å¼€å§‹æ‰§è¡Œperform_validationå‡½æ•°...")
    
    buffer = io.StringIO()
    
    eligible = [u for u in valid_players if len(user_history_map[u]) >= look_back + 1]
    if len(eligible) < sample_size: sample_size = len(eligible)
    print(f"ğŸ” ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·æ•°é‡: {len(eligible)}, æŠ½æ ·æ•°é‡: {sample_size}")
    
    # æ›´æ–°è¾“å‡ºè·¯å¾„ä¿¡æ¯
    buffer.write(f"\nStep 5: å¯åŠ¨å›æµ‹éªŒè¯æŠ½æ ·æŠ¥å‘Š (æ ·æœ¬æ•°={sample_size}, è¾“å‡ºè‡³ outputs/lstm_output.txt)...")
    
    header = f"{'User ID':<10} | {'Bias':<5} | {'Diff':<5} | {'Real':<5} | {'Pred':<5} | {'Err':<5} | {'Status'}"
    buffer.write("\n" + "-" * 70 + "\n" + header + "\n" + "-" * 70)
    
    # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç”¨æˆ·è¿›è¡ŒæŠ½æ ·
    if len(eligible) > 0:
        report_users = random.sample(eligible, min(10, sample_size))
        print(f"ğŸ” å·²æŠ½å– {len(report_users)} ä¸ªç”¨æˆ·è¿›è¡Œå±•ç¤º")
        
        large_errors = 0
        
        for i, user in enumerate(report_users):
            full_hist = user_history_map[user]
            # è·å–ç›®æ ‡æ•°æ® (Trial, Difficulty, WordID, UserBias)
            target_data = full_hist[-1]
            
            real_trial = float(target_data[0])
            t_diff = target_data[1]; t_word = target_data[2]; t_bias = target_data[3]
            
            try:
                # ä¸´æ—¶è¿›è¡Œå•æ ·æœ¬é¢„æµ‹ä»¥è·å¾—è¯¥ç”¨æˆ·çš„é¢„æµ‹å€¼
                temp_inputs = prepare_single_inference_input(full_hist[-(look_back+1) : -1], t_diff, t_word, t_bias, look_back)
                pred_probs, _ = model.predict(temp_inputs, verbose=0)
                
                # è·å–é¢„æµ‹çš„ç±»åˆ« (1-7)
                pred_discrete = np.argmax(pred_probs[0]) + 1  # +1å› ä¸ºç´¢å¼•ä»0å¼€å§‹ï¼Œæ­¥æ•°ä»1å¼€å§‹
                
                # è®¡ç®—ç±»åˆ«è¯¯å·®
                err = abs(pred_discrete - real_trial)
                
                if err > threshold: large_errors += 1
                
                status = "âœ…" if err == 0 else "âš ï¸"
                if err > threshold: status = "âŒ"
                line = f"{str(user):<10} | {t_bias:.2f}  | {t_diff:.2f}  | {real_trial:.0f}    | {pred_discrete}      | {err}        | {status}"
                buffer.write(f"\n{line}")
            except Exception as e:
                print(f"âŒ å¤„ç†ç”¨æˆ· {user} æ—¶å‡ºé”™: {e}")
                buffer.write(f"\n{str(user):<10} | é”™è¯¯: {str(e)[:20]}...")

        if sample_size > len(report_users):
            buffer.write(f"\n... (å…¶ä½™ {sample_size - len(report_users)} æ¡çœç•¥)")
    else:
        buffer.write("\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·æ•°æ®è¿›è¡ŒæŠ½æ ·")
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·æ•°æ®è¿›è¡ŒæŠ½æ ·")
    
    # æ‰“å°åˆ°æ§åˆ¶å°
    report_content = buffer.getvalue()
    print(report_content)
    
    # å†™å…¥æ–‡ä»¶ï¼Œç¡®ä¿æ–‡ä»¶å­˜åœ¨
    try:
        os.makedirs('outputs', exist_ok=True)
        with open("outputs/lstm_output.txt", "a", encoding="utf-8") as f: # è¿½åŠ åˆ°æŠ¥å‘Š
            f.write(report_content)
        print("\nâœ… æŠ½æ ·æŠ¥å‘Šå·²æˆåŠŸå¯¼å‡ºè‡³ outputs/lstm_output.txt æ–‡ä»¶ã€‚")
    except Exception as e:
        print(f"\nâŒ å†™å…¥æŠ½æ ·æŠ¥å‘Šå¤±è´¥: {e}")

def plot_confusion_matrix(true_labels, pred_labels, model_name, save_dir):
    """ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ"""
    # ç”Ÿæˆæ··æ·†çŸ©é˜µ
    cm = confusion_matrix(true_labels, pred_labels)
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ç™¾åˆ†æ¯”
    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100
    
    plt.figure(figsize=(10, 8))
    plt.imshow(cm_percent, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'{model_name} æ··æ·†çŸ©é˜µ (%)')
    plt.colorbar()
    
    # è®¾ç½®æ ‡ç­¾
    classes = list(range(1, 8))
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes)
    plt.yticks(tick_marks, classes)
    
    # åœ¨æ··æ·†çŸ©é˜µä¸­æ·»åŠ ç™¾åˆ†æ¯”æ–‡æœ¬
    fmt = '.1f'
    thresh = cm_percent.max() / 2.
    for i in range(cm_percent.shape[0]):
        for j in range(cm_percent.shape[1]):
            plt.text(j, i, format(cm_percent[i, j], fmt),
                    horizontalalignment="center",
                    color="white" if cm_percent[i, j] > thresh else "black")
    
    plt.ylabel('çœŸå®æ­¥æ•°')
    plt.xlabel('é¢„æµ‹æ­¥æ•°')
    plt.tight_layout()
    
    # ä¿å­˜æ··æ·†çŸ©é˜µ
    save_path = os.path.join(save_dir, f'{model_name}_confusion_matrix.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜è‡³: {save_path}")
    return save_path


# ==========================================
# 4. ä¸»ç¨‹åº (Main)
# ==========================================

def plot_loss_curve(history, model_name, save_dir):
    """ç»˜åˆ¶å¹¶ä¿å­˜Lossæ›²çº¿å’Œå‡†ç¡®ç‡æ›²çº¿"""
    plt.figure(figsize=(14, 10))
    
    # ç»˜åˆ¶æ€»æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 1)
    plt.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
    plt.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
    plt.title(f'{model_name} æ€»æŸå¤±æ›²çº¿')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    # ç»˜åˆ¶æ­¥æ•°é¢„æµ‹æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 2)
    plt.plot(history.history['output_steps_loss'], label='è®­ç»ƒæ­¥æ•°æŸå¤±')
    plt.plot(history.history['val_output_steps_loss'], label='éªŒè¯æ­¥æ•°æŸå¤±')
    plt.title(f'{model_name} æ­¥æ•°é¢„æµ‹æŸå¤±')
    plt.xlabel('Epoch')
    plt.ylabel('åˆ†ç±»æŸå¤± (Categorical Crossentropy)')
    plt.legend()
    plt.grid(True)
    
    # ç»˜åˆ¶æ­¥æ•°é¢„æµ‹å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(2, 2, 3)
    plt.plot(history.history['output_steps_accuracy'], label='è®­ç»ƒæ­¥æ•°å‡†ç¡®ç‡')
    plt.plot(history.history['val_output_steps_accuracy'], label='éªŒè¯æ­¥æ•°å‡†ç¡®ç‡')
    plt.title(f'{model_name} æ­¥æ•°é¢„æµ‹å‡†ç¡®ç‡')
    plt.xlabel('Epoch')
    plt.ylabel('å‡†ç¡®ç‡')
    plt.ylim(0, 1)
    plt.legend()
    plt.grid(True)
    
    # ç»˜åˆ¶æˆåŠŸé¢„æµ‹å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(2, 2, 4)
    plt.plot(history.history['output_success_accuracy'], label='è®­ç»ƒæˆåŠŸé¢„æµ‹å‡†ç¡®ç‡')
    plt.plot(history.history['val_output_success_accuracy'], label='éªŒè¯æˆåŠŸé¢„æµ‹å‡†ç¡®ç‡')
    plt.title(f'{model_name} æˆåŠŸé¢„æµ‹å‡†ç¡®ç‡')
    plt.xlabel('Epoch')
    plt.ylabel('å‡†ç¡®ç‡')
    plt.ylim(0, 1)
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, f'{model_name}_loss_curve.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… Lossæ›²çº¿å·²ä¿å­˜è‡³: {save_path}")
    return save_path

def plot_prediction_trends(true_steps, pred_steps, model_name, save_dir):
    """ç»˜åˆ¶é¢„æµ‹ç»“æœè¶‹åŠ¿å›¾"""
    # éšæœºé€‰æ‹©100ä¸ªæ ·æœ¬è¿›è¡Œå¯è§†åŒ–ï¼Œé¿å…å›¾è¿‡äºæ‹¥æŒ¤
    if len(true_steps) > 100:
        indices = np.random.choice(len(true_steps), 100, replace=False)
        true_sample = true_steps[indices]
        pred_sample = pred_steps[indices]
    else:
        true_sample = true_steps
        pred_sample = pred_steps
    
    # æŒ‰çœŸå®å€¼æ’åº
    sorted_indices = np.argsort(true_sample)
    true_sample_sorted = true_sample[sorted_indices]
    pred_sample_sorted = pred_sample[sorted_indices]
    
    plt.figure(figsize=(12, 6))
    
    # ç»˜åˆ¶é¢„æµ‹å€¼ä¸çœŸå®å€¼å¯¹æ¯”å›¾
    plt.subplot(1, 2, 1)
    plt.scatter(true_sample, pred_sample, alpha=0.5, s=50)
    plt.plot([0, 7], [0, 7], 'r--', lw=2)  # ç†æƒ³çº¿
    plt.title(f'{model_name} é¢„æµ‹å€¼ vs çœŸå®å€¼')
    plt.xlabel('çœŸå®æ­¥æ•°')
    plt.ylabel('é¢„æµ‹æ­¥æ•°')
    plt.grid(True)
    plt.xlim(0, 7)
    plt.ylim(0, 7)
    
    # ç»˜åˆ¶æ’åºåçš„é¢„æµ‹è¶‹åŠ¿
    plt.subplot(1, 2, 2)
    plt.plot(range(len(true_sample_sorted)), true_sample_sorted, 'b-', label='çœŸå®å€¼')
    plt.plot(range(len(pred_sample_sorted)), pred_sample_sorted, 'r--', label='é¢„æµ‹å€¼')
    plt.title(f'{model_name} é¢„æµ‹è¶‹åŠ¿')
    plt.xlabel('æ ·æœ¬ç´¢å¼• (æŒ‰çœŸå®å€¼æ’åº)')
    plt.ylabel('æ­¥æ•°')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, f'{model_name}_prediction_trends.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… é¢„æµ‹è¶‹åŠ¿å›¾å·²ä¿å­˜è‡³: {save_path}")
    return save_path

def train_model():
    """
    è®­ç»ƒæ¨¡å‹å‡½æ•°
    """
    # --- GPU è®¾ç½® ---
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)
            set_global_policy('mixed_float16')
            print("âœ… GPU åŠ é€Ÿå·²å¼€å¯ (Mixed Float16)")
        except: pass
    
    # ç¡®ä¿å¯è§†åŒ–æ–‡ä»¶å¤¹å­˜åœ¨
    visualization_dir = 'visualization'
    os.makedirs(visualization_dir, exist_ok=True)
    os.makedirs('outputs', exist_ok=True)
    
    # --- åˆå§‹åŒ– WandB ---
    global wandb_run
    if WANDB_ENABLED:
        print("ğŸ”„ åˆå§‹åŒ– WandB å®éªŒè®°å½•...")
        try:
            # ä½¿ç”¨ç¦»çº¿æ¨¡å¼é¿å…ç½‘ç»œè¿æ¥é—®é¢˜
            wandb_run = wandb.init(
                project=WANDB_PROJECT, 
                name=WANDB_RUN_NAME, 
                dir='wandb', 
                anonymous='must',
                resume=False,
                mode='offline',  # æ·»åŠ ç¦»çº¿æ¨¡å¼
                settings=wandb.Settings(
                    start_method='thread',
                    disable_git=True,
                    disable_code=True
                )
            )
            # è®°å½•è¶…å‚æ•°
            config = wandb_run.config
            print("âœ… WandB åˆå§‹åŒ–æˆåŠŸï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
        except Exception as e:
            print(f"âŒ WandB åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            print("â„¹ï¸  ç¨‹åºå°†åœ¨ä¸ä½¿ç”¨ WandB çš„æƒ…å†µä¸‹ç»§ç»­è¿è¡Œ")
            WANDB_ENABLED = False
            wandb_run = None
            config = {}
    else:
        print("â„¹ï¸  WandB å·²è¢«ç¦ç”¨")
        config = {}
    config.look_back = LOOK_BACK
    config.epochs = EPOCHS
    config.batch_size = BATCH_SIZE
    config.embedding_dim = EMBEDDING_DIM
    config.large_error_threshold = LARGE_ERROR_THRESHOLD
        
    # 1. æ•°æ®å¤„ç†
    user_map, vocab_size, _, _ = process_data_and_extract_features(FILE_PATH, MAX_ROWS)
    if not user_map: return None, None, None, None, None, None, None, None

    # 2. æ•°æ®é›†æ„å»º
    X_s, X_d, X_w, X_b, y_st, y_su, valid_users = create_multi_input_dataset(user_map, LOOK_BACK)
    
    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›† = 7:1:2
    indices = np.arange(len(y_st))
    # å…ˆåˆ’åˆ†è®­ç»ƒé›†å’Œå‰©ä½™æ•°æ®
    train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=42)
    # å†ä»å‰©ä½™æ•°æ®ä¸­åˆ’åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†
    val_idx, test_idx = train_test_split(temp_idx, test_size=2/3, random_state=42)  # 1:2
    
    print(f"æ•°æ®é›†åˆ’åˆ†ï¼šè®­ç»ƒé›† {len(train_idx)}, éªŒè¯é›† {len(val_idx)}, æµ‹è¯•é›† {len(test_idx)}")
    
    return (X_s, X_d, X_w, X_b, y_st, y_su, valid_users, train_idx, val_idx, test_idx, 
            vocab_size, user_map, visualization_dir, config)
    
def build_and_train_model(X_s, X_d, X_w, X_b, y_st, y_su, train_idx, val_idx, test_idx, 
                          vocab_size, visualization_dir, config):
    """
    æ„å»ºå¹¶è®­ç»ƒæ¨¡å‹
    """
    # æ„å»º TF Dataset è¾…åŠ©å‡½æ•°
    def make_ds(idx):
        return tf.data.Dataset.from_tensor_slices((
            {
                'input_history': X_s[idx],
                'input_difficulty': X_d[idx],
                'input_word_id': X_w[idx],
                'input_user_bias': X_b[idx]
            },
            {
                'output_steps': y_st[idx],
                'output_success': y_su[idx]
            }
        )).shuffle(20000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
        
    train_ds = make_ds(train_idx)
    # val_ds ç”¨äºæ¨¡å‹è¯„ä¼°ï¼Œä¸éœ€è¦ shuffle
    val_ds = tf.data.Dataset.from_tensor_slices((
            {
                'input_history': X_s[val_idx],
                'input_difficulty': X_d[val_idx],
                'input_word_id': X_w[val_idx],
                'input_user_bias': X_b[val_idx]
            },
            {
                'output_steps': y_st[val_idx],
                'output_success': y_su[val_idx]
            }
        )).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
    
    # æµ‹è¯•é›†ä¹Ÿä¸éœ€è¦shuffle
    test_ds = tf.data.Dataset.from_tensor_slices((
            {
                'input_history': X_s[test_idx],
                'input_difficulty': X_d[test_idx],
                'input_word_id': X_w[test_idx],
                'input_user_bias': X_b[test_idx]
            },
            {
                'output_steps': y_st[test_idx],
                'output_success': y_su[test_idx]
            }
        )).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
    
    # 3. æ¨¡å‹æ„å»ºä¸è®­ç»ƒ/åŠ è½½
    is_trained = False
    model = None
    
    if os.path.exists(MODEL_SAVE_PATH):
        print(f"Step 3: æ£€æµ‹åˆ°å·²ä¿å­˜æ¨¡å‹ {MODEL_SAVE_PATH}ï¼Œå°è¯•åŠ è½½...")
        try:
            model = tf.keras.models.load_model(MODEL_SAVE_PATH)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè·³è¿‡è®­ç»ƒã€‚")
            is_trained = True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}. å°†é‡æ–°æ„å»ºå¹¶è®­ç»ƒæ¨¡å‹ã€‚")
            is_trained = False
            
    if not is_trained:
        # æ„å»ºæ¨¡å‹
        model = build_context_model(LOOK_BACK, vocab_size, EMBEDDING_DIM)
        
        # åˆ›å»ºæ—©åœå›è°ƒ
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=PATIENCE,
            restore_best_weights=True,
            verbose=1
        )
        
        # è®­ç»ƒ
        print(f"Step 4: å¼€å§‹è®­ç»ƒ (Epochs={EPOCHS}, Batch={BATCH_SIZE})...")
          # æ„å»ºå›è°ƒåˆ—è¡¨
          callbacks = [early_stopping]
          if WANDB_ENABLED and wandb_run is not None:
              callbacks.append(WandbCallback(save_model=False))
          
          history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, verbose=1,
                            callbacks=callbacks)
            
        # è®­ç»ƒå®Œæˆåä¿å­˜
        try:
            model.save(MODEL_SAVE_PATH)
            print(f"\nâœ… æ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶å¤¹: {MODEL_SAVE_PATH}")
        except Exception as save_e:
            print(f"\nâŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {save_e}")
        
        # ç»˜åˆ¶å¹¶ä¿å­˜Lossæ›²çº¿
        loss_curve_path = plot_loss_curve(history, 'LSTM', visualization_dir)
        # è®°å½•åˆ°WandB
        if WANDB_ENABLED and wandb_run is not None:
            try:
                wandb.log({'loss_curve': wandb.Image(loss_curve_path)})
            except Exception as e:
                print(f"âŒ WandB æ—¥å¿—è®°å½•å¤±è´¥: {str(e)}")
        
    # è®­ç»ƒå®Œæˆåä¿å­˜
    try:
        model.save(MODEL_SAVE_PATH)
        print(f"\nâœ… æ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶å¤¹: {MODEL_SAVE_PATH}")
    except Exception as save_e:
        print(f"\nâŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {save_e}")
        
    return model, val_idx, test_idx
        
def evaluate_model(model, X_s, X_d, X_w, X_b, y_st, y_su, valid_users, user_map, 
                  val_idx, test_idx, visualization_dir, config):
    """
    è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸Šçš„è¡¨ç°
    """
    # éªŒè¯é›†è¯„ä¼°
    val_inputs = {
        'input_history': X_s[val_idx],
        'input_difficulty': X_d[val_idx],
        'input_word_id': X_w[val_idx],
        'input_user_bias': X_b[val_idx]
    }
    val_labels = {
        'output_steps': y_st[val_idx],
        'output_success': y_su[val_idx]
    }

    val_pred_probs, val_pred_discrete, val_true_discrete, val_pred_success_prob = evaluate_model_and_get_preds(model, val_inputs, val_labels)

    # è®¡ç®— ACC å’Œ AUC
    val_true_wins = val_labels['output_success']
    val_pred_wins = (val_pred_success_prob >= 0.5).astype(int)
    val_acc = accuracy_score(val_true_wins, val_pred_wins)
    
    # è®¡ç®— AUC
    try:
        val_auc = roc_auc_score(val_true_wins, val_pred_success_prob)
    except ValueError:
        print("âš ï¸ AUC è®¡ç®—å¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ­£è´Ÿæ ·æœ¬ä¸å¹³è¡¡æˆ–ä»…æœ‰å•ä¸€ç±»åˆ«")
        val_auc = 0.5  # é»˜è®¤å€¼
    
    # è®¡ç®—å¤§å‹è¯¯å·®ç‡
    val_large_error_rate = np.mean(np.abs(val_labels['output_steps'] - val_pred_steps) > LARGE_ERROR_THRESHOLD)
    
    # è®¡ç®—ç¦»æ•£é¢„æµ‹çš„ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1å€¼
    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(
        val_true_discrete, val_pred_discrete, average='macro', zero_division=0
    )
    
    # æµ‹è¯•é›†è¯„ä¼°
    test_inputs = {
        'input_history': X_s[test_idx],
        'input_difficulty': X_d[test_idx],
        'input_word_id': X_w[test_idx],
        'input_user_bias': X_b[test_idx]
    }
    test_labels = {
        'output_steps': y_st[test_idx],
        'output_success': y_su[test_idx]
    }

    test_pred_probs, test_pred_discrete, test_true_discrete, test_pred_success_prob = evaluate_model_and_get_preds(model, test_inputs, test_labels)

    # è®¡ç®—æµ‹è¯•é›† ACC å’Œ AUC
    test_true_wins = test_labels['output_success']
    test_pred_wins = (test_pred_success_prob >= 0.5).astype(int)
    test_acc = accuracy_score(test_true_wins, test_pred_wins)
    
    # è®¡ç®—æµ‹è¯•é›† AUC
    try:
        test_auc = roc_auc_score(test_true_wins, test_pred_success_prob)
    except ValueError:
        print("âš ï¸ æµ‹è¯•é›† AUC è®¡ç®—å¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ­£è´Ÿæ ·æœ¬ä¸å¹³è¡¡æˆ–ä»…æœ‰å•ä¸€ç±»åˆ«")
        test_auc = 0.5  # é»˜è®¤å€¼
    
    # è®¡ç®—æµ‹è¯•é›†å¤§å‹è¯¯å·®ç‡
    test_large_error_rate = np.mean(np.abs(test_labels['output_steps'] - test_pred_steps) > LARGE_ERROR_THRESHOLD)
    
    # è®¡ç®—æµ‹è¯•é›†ç¦»æ•£é¢„æµ‹çš„ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1å€¼
    test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(
        test_true_discrete, test_pred_discrete, average='macro', zero_division=0
    )
    
    # è®°å½•éªŒè¯æŒ‡æ ‡åˆ° WandB
    if WANDB_ENABLED and wandb_run is not None:
        try:
            wandb.log({
                "val_accuracy": val_acc,
                "val_auc": val_auc,
                "val_large_error_rate": val_large_error_rate,
                "val_precision": val_precision,
                "val_recall": val_recall,
                "val_f1": val_f1,
                "test_accuracy": test_acc,
                "test_auc": test_auc,
                "test_large_error_rate": test_large_error_rate,
                "test_precision": test_precision,
                "test_recall": test_recall,
                "test_f1": test_f1
            })
        except Exception as e:
            print(f"âŒ WandB æ—¥å¿—è®°å½•å¤±è´¥: {str(e)}")
    
    # ç”ŸæˆæŠ¥å‘Šçš„å¤´éƒ¨å’Œæ±‡æ€»æŒ‡æ ‡
    report = f"""
========================================
  LSTMæ¨¡å‹éªŒè¯å’Œæµ‹è¯•æŠ¥å‘Š
========================================
---- éªŒè¯é›†æŒ‡æ ‡ ----
3. èƒœè´Ÿé¢„æµ‹å‡†ç¡®ç‡        : {val_acc:.3%}
4. ROCæ›²çº¿ä¸‹é¢ç§¯ (AUC)   : {val_auc:.4f}
5. å¤§å‹è¯¯å·®ç‡ (>{LARGE_ERROR_THRESHOLD}æ­¥)  : {val_large_error_rate:.3%}
6. ç²¾ç¡®ç‡ (Precision)    : {val_precision:.4f}
7. å¬å›ç‡ (Recall)       : {val_recall:.4f}
8. F1å€¼ (F1-Score)       : {val_f1:.4f}

---- æµ‹è¯•é›†æŒ‡æ ‡ ----
3. èƒœè´Ÿé¢„æµ‹å‡†ç¡®ç‡        : {test_acc:.3%}
4. ROCæ›²çº¿ä¸‹é¢ç§¯ (AUC)   : {test_auc:.4f}
5. å¤§å‹è¯¯å·®ç‡ (>{LARGE_ERROR_THRESHOLD}æ­¥)  : {test_large_error_rate:.3%}
6. ç²¾ç¡®ç‡ (Precision)    : {test_precision:.4f}
7. å¬å›ç‡ (Recall)       : {test_recall:.4f}
8. F1å€¼ (F1-Score)       : {test_f1:.4f}
========================================
"""
    # æ¸…ç©º output.txt å¹¶å†™å…¥å…¨å±€æŠ¥å‘Š
    with open("outputs/lstm_output.txt", "w", encoding="utf-8") as f:
        f.write(report)
    print(report)
    
    # è°ƒç”¨ perform_validation è¿›è¡ŒæŠ½æ ·æŠ¥å‘Šï¼ˆä½¿ç”¨æµ‹è¯•é›†é¢„æµ‹ç»“æœï¼‰
    perform_validation(model, user_map, valid_users, LOOK_BACK, 
                       min(10000, len(test_idx)), LARGE_ERROR_THRESHOLD, test_pred_steps)
    
    # ç»˜åˆ¶å¹¶ä¿å­˜é¢„æµ‹è¶‹åŠ¿å›¾ï¼ˆä½¿ç”¨æµ‹è¯•é›†ç»“æœï¼‰
    prediction_trend_path = plot_prediction_trends(
        test_labels['output_steps'], test_pred_steps, 'LSTM', visualization_dir
    )
    # è®°å½•åˆ°WandB
    if WANDB_ENABLED and wandb_run is not None:
        try:
            wandb.log({'prediction_trends': wandb.Image(prediction_trend_path)})
        except Exception as e:
            print(f"âŒ WandB æ—¥å¿—è®°å½•å¤±è´¥: {str(e)}")
    
    # ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µï¼ˆä½¿ç”¨æµ‹è¯•é›†ç¦»æ•£åŒ–ç»“æœï¼‰
    cm_path = plot_confusion_matrix(test_true_discrete, test_pred_discrete, 'LSTM', visualization_dir)
    if WANDB_ENABLED and wandb_run is not None:
        try:
            wandb.log({'confusion_matrix': wandb.Image(cm_path)})
        except Exception as e:
            print(f"âŒ WandB æ—¥å¿—è®°å½•å¤±è´¥: {str(e)}")
    
    return model

def predict_with_model(model, user_history_map, user_id, look_back):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
    
    å‚æ•°:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    user_history_map: ç”¨æˆ·å†å²æ•°æ®æ˜ å°„
    user_id: è¦é¢„æµ‹çš„ç”¨æˆ·ID
    look_back: å†å²çª—å£å¤§å°
    
    è¿”å›:
    é¢„æµ‹çš„æ­¥æ•°ã€ç¦»æ•£åŒ–çš„é¢„æµ‹æ­¥æ•°å’ŒæˆåŠŸæ¦‚ç‡
    """
    if user_id not in user_history_map or len(user_history_map[user_id]) < look_back + 1:
        print(f"âš ï¸ ç”¨æˆ· {user_id} æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
        return None, None, None
    
    full_hist = user_history_map[user_id]
    # è·å–ç›®æ ‡æ•°æ® (Trial, Difficulty, WordID, UserBias)
    target_data = full_hist[-1]
    t_diff = target_data[1]; t_word = target_data[2]; t_bias = target_data[3]
    
    # å‡†å¤‡è¾“å…¥æ•°æ®
    inputs = prepare_single_inference_input(full_hist[-(look_back+1) : -1], t_diff, t_word, t_bias, look_back)
    pred_steps, pred_success = model.predict(inputs, verbose=0)
    
    # è®¡ç®—ç¦»æ•£åŒ–çš„é¢„æµ‹å€¼
    pred_continuous = min(pred_steps[0][0], 6.99)
    pred_discrete = int(round(pred_continuous))
    pred_discrete = max(1, min(7, pred_discrete))
    
    return pred_continuous, pred_discrete, pred_success[0][0]

def main(mode='train', user_id=None):
    """
    ä¸»å‡½æ•°
    
    å‚æ•°:
    mode: 'train' æˆ– 'predict'
    user_id: å½“modeä¸º'predict'æ—¶ï¼ŒæŒ‡å®šè¦é¢„æµ‹çš„ç”¨æˆ·ID
    """
    if mode == 'train':
        # è®­ç»ƒæ¨¡å¼
        data = train_model()
        if data[0] is None:  # æ•°æ®åŠ è½½å¤±è´¥
            return
        
        X_s, X_d, X_w, X_b, y_st, y_su, valid_users, train_idx, val_idx, test_idx, \
        vocab_size, user_map, visualization_dir, config = data
        
        model, val_idx, test_idx = build_and_train_model(
            X_s, X_d, X_w, X_b, y_st, y_su, train_idx, val_idx, test_idx,
            vocab_size, visualization_dir, config
        )
        
        evaluate_model(
            model, X_s, X_d, X_w, X_b, y_st, y_su, valid_users, user_map,
            val_idx, test_idx, visualization_dir, config
        )
        
        # å®Œæˆ WandB å®éªŒè®°å½•
        wandb.finish()
        print("âœ… WandB å®éªŒè®°å½•å·²å®Œæˆ")
        print(f"âœ… æ‰€æœ‰å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³: {visualization_dir}")
        
    elif mode == 'predict':
        # é¢„æµ‹æ¨¡å¼
        if not user_id:
            print("âŒ é¢„æµ‹æ¨¡å¼éœ€è¦æŒ‡å®š user_id å‚æ•°")
            return
        
        # åŠ è½½æ¨¡å‹
        if not os.path.exists(MODEL_SAVE_PATH):
            print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {MODEL_SAVE_PATH}")
            return
        
        try:
            model = tf.keras.models.load_model(MODEL_SAVE_PATH)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # åŠ è½½æ•°æ®è¿›è¡Œé¢„æµ‹
            user_map, _, _, _ = process_data_and_extract_features(FILE_PATH, MAX_ROWS)
            if not user_map:
                print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
                return
            
            # è¿›è¡Œé¢„æµ‹
            pred_continuous, pred_discrete, pred_success = predict_with_model(model, user_map, user_id, LOOK_BACK)
            if pred_continuous is not None:
                print(f"\nç”¨æˆ· {user_id} çš„é¢„æµ‹ç»“æœ:")
                print(f"é¢„æµ‹æ­¥æ•°(è¿ç»­): {pred_continuous:.2f}")
                print(f"é¢„æµ‹æ­¥æ•°(ç¦»æ•£): {pred_discrete}")
                print(f"æˆåŠŸæ¦‚ç‡: {pred_success:.2%}")
                print(f"é¢„æµ‹ç»“æœ: {'æˆåŠŸ' if pred_continuous <= 6 else 'å¤±è´¥'}")
                
        except Exception as e:
            print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    else:
        print(f"âŒ æœªçŸ¥æ¨¡å¼: {mode}ï¼Œè¯·ä½¿ç”¨ 'train' æˆ– 'predict'")

if __name__ == "__main__":
    # ç¡®ä¿å¿…è¦çš„æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs('wandb', exist_ok=True)
    os.makedirs('visualization', exist_ok=True)
    os.makedirs('outputs', exist_ok=True)
    main()