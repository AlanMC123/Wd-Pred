#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ„ç‰ˆ LSTM å¤šè¾“å…¥é¢„æµ‹è„šæœ¬ï¼ˆç¨³å®šç‰ˆï¼‰
ä¸éœ€è¦ CLI æˆ– parse_argsï¼Œç›´æ¥è¿è¡Œå³å¼€å§‹è®­ç»ƒã€‚
é¢„æµ‹æ¨¡å¼å¯ä»¥é€šè¿‡ä¿®æ”¹ main() ä¸‹æ–¹çš„ä¸€è¡Œå¼€å…³æ¥å¯ç”¨ã€‚
"""

import os
import json
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import wandb
from wandb.integration.keras import WandbCallback
from typing import Dict, Tuple, List
from tensorflow.keras.layers import (Input, Dense, Dropout, Embedding, Flatten,
                                     LSTM, Bidirectional, Concatenate)
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, roc_auc_score, roc_curve

# ==========================================================
# å…¨å±€é…ç½®
# ==========================================================

TRAIN_FILE = "dataset/train_data.csv"
VAL_FILE = "dataset/val_data.csv"
TEST_FILE = "dataset/test_data.csv"

DIFFICULTY_FILE = "dataset/difficulty.csv"
PLAYER_FILE = "dataset/player_data.csv"

LOOK_BACK = 8
BATCH_SIZE = 1024
EPOCHS = 15
LEARNING_RATE = 0.001

MODEL_SAVE_PATH = "models/lstm/lstm_model.keras"
TOKENIZER_PATH = "models/lstm/lstm_tokenizer.json"

# LSTM æ¶æ„å‚æ•°
LSTM_UNITS = 64
DROPOUT_RATE = 0.15
EMBEDDING_DIM = 24

OOV_TOKEN = "<OOV>"

LARGE_ERROR_THRESHOLD = 1.5
PATIENCE = 5
REPORT_SAVE_PATH = "outputs/lstm_output.txt"

# å›ºå®šéšæœºç§å­
SEED = 42

# ==========================================================
# å·¥å…·å‡½æ•°
# ==========================================================

def set_seed(seed):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    # è®¾ç½®ç¡®å®šæ€§æ“ä½œ
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

def ensure_dirs():
    os.makedirs(os.path.dirname(MODEL_SAVE_PATH) or ".", exist_ok=True)
    os.makedirs("outputs", exist_ok=True)
    os.makedirs("models/lstm", exist_ok=True)
    os.makedirs("visualization", exist_ok=True)





def safe_read_csv(path, usecols=None):
    if not os.path.exists(path):
        raise FileNotFoundError(f"File missing: {path}")
    return pd.read_csv(path, usecols=usecols)


def fit_tokenizer(train_df):
    tokenizer = Tokenizer(oov_token=OOV_TOKEN, filters='', lower=True)
    tokenizer.fit_on_texts(train_df["target"].astype(str))
    with open(TOKENIZER_PATH, "w", encoding="utf-8") as f:
        json.dump(tokenizer.word_index, f, indent=2)
    return tokenizer


def load_tokenizer():
    with open(TOKENIZER_PATH, "r", encoding="utf-8") as f:
        word_index = json.load(f)
    tk = Tokenizer(oov_token=OOV_TOKEN)
    tk.word_index = word_index
    return tk


def attach_features(df, tokenizer, diff_map, user_map):
    df = df.copy()
    df["target"] = df["target"].astype(str)
    seqs = tokenizer.texts_to_sequences(df["target"])
    df["word_id"] = [s[0] if s else 0 for s in seqs]
    df["word_difficulty"] = df["target"].map(diff_map).fillna(4.0).astype(float)
    df["user_bias"] = df["Username"].map(user_map).fillna(4.0).astype(float)
    return df


def build_history(df) -> Dict[str, List[Tuple]]:
    hist = {}
    df_sorted = df.sort_values(["Username", "Game"])
    for u, g in df_sorted.groupby("Username", sort=False):
        hist[u] = [(int(r["Trial"]),
                    float(r["word_difficulty"]),
                    int(r["word_id"]),
                    float(r["user_bias"]))
                   for _, r in g.iterrows()]
    return hist


def create_samples(history, look_back):
    X_seq, X_diff, X_wid, X_bias, y_steps, y_succ = [], [], [], [], [], []
    for user, events in history.items():
        if len(events) <= look_back:
            continue
        for i in range(look_back, len(events)):
            window = events[i-look_back:i]
            target = events[i]

            trials = np.array([t[0] for t in window], np.float32)
            norm = trials / 7.0
            std = np.std(trials) / 7.0

            seq = np.stack([norm, np.full_like(norm, std)], axis=1)
            X_seq.append(seq)
            X_diff.append([target[1] / 7.0])
            X_wid.append([target[2]])
            X_bias.append([target[3] / 7.0])
            y_steps.append(min(float(target[0]), 7.0))
            y_succ.append(1.0 if target[0] <= 6 else 0.0)

    if not X_seq:
        return (np.zeros((0, look_back, 2), np.float32),
                np.zeros((0, 1), np.float32),
                np.zeros((0, 1), np.int32),
                np.zeros((0, 1), np.float32),
                np.zeros((0,), np.float32),
                np.zeros((0,), np.float32))

    return (
        np.array(X_seq, np.float32),
        np.array(X_diff, np.float32),
        np.array(X_wid, np.int32),
        np.array(X_bias, np.float32),
        np.array(y_steps, np.float32),
        np.array(y_succ, np.float32)
    )


# ==========================================================
# LSTM æ¨¡å‹
# ==========================================================

def build_model(look_back, vocab_size):
    # å†å²è¾“å…¥åˆ†æ”¯
    h_in = Input((look_back, 2), name="input_history")
    # ä½¿ç”¨åŒå‘LSTMå¤„ç†å†å²åºåˆ—
    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(h_in)
    x = Dropout(DROPOUT_RATE)(x)
    x = Bidirectional(LSTM(LSTM_UNITS // 2))(x)
    x = Dropout(DROPOUT_RATE)(x)

    # éš¾åº¦è¾“å…¥åˆ†æ”¯
    diff_in = Input((1,), name="input_difficulty")
    d1 = Dense(16, activation="relu")(diff_in)

    # å•è¯IDè¾“å…¥åˆ†æ”¯
    wid_in = Input((1,), name="input_word_id", dtype="int32")
    wemb = Flatten()(Embedding(vocab_size, EMBEDDING_DIM)(wid_in))

    # ç”¨æˆ·åç½®è¾“å…¥åˆ†æ”¯
    bias_in = Input((1,), name="input_user_bias")
    b1 = Dense(16, activation="relu")(bias_in)

    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    z = Concatenate()([x, d1, wemb, b1])
    z = Dense(64, activation="relu")(z)
    z = Dropout(DROPOUT_RATE)(z)

    # è¾“å‡ºå±‚
    out_steps = Dense(1, "linear", name="output_steps")(Dense(32, "relu")(z))
    out_succ = Dense(1, "sigmoid", name="output_success")(Dense(16, "relu")(z))

    model = Model([h_in, diff_in, wid_in, bias_in], [out_steps, out_succ])
    model.compile(
        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),
        loss={"output_steps": "mse",
              "output_success": "binary_crossentropy"},
        loss_weights={"output_steps": 1.0, "output_success": 0.5},
        metrics={"output_success": "accuracy"}
    )
    return model


# ==========================================================
# è¯„ä¼°å‡½æ•°
# ==========================================================

def evaluate_model(model, Xs):
    X_seq, X_diff, X_wid, X_bias, y_steps, y_succ = Xs
    pred_steps, pred_prob = model.predict({
        "input_history": X_seq,
        "input_difficulty": X_diff,
        "input_word_id": X_wid,
        "input_user_bias": X_bias
    }, batch_size=1024, verbose=1)
    pred_steps = pred_steps.flatten()
    pred_prob = pred_prob.flatten()

    mae = mean_absolute_error(y_steps, np.clip(pred_steps, 0, 7))
    rmse = np.sqrt(mean_squared_error(y_steps, np.clip(pred_steps, 0, 7)))
    acc = accuracy_score(y_succ.astype(int), (pred_prob >= 0.5).astype(int))
    try:
        auc = roc_auc_score(y_succ, pred_prob)
    except:
        auc = float("nan")

    print(f"MAE={mae:.4f}, RMSE={rmse:.4f}, ACC={acc:.4f}, AUC={auc}")
    return mae, rmse, acc, auc

def compute_large_error_rate(y_true, y_pred, threshold):
    errors = np.abs(y_true - y_pred)
    return np.mean(errors > threshold)


def plot_roc_curve(y_true, y_pred, save_path):
    """Plot ROC AUC curve"""
    fpr, tpr, _ = roc_curve(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc_score(y_true, y_pred):.3f})')
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.grid(True, alpha=0.3)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"AUC curve saved to: {save_path}")

def plot_loss(history, save_path):
    """Plot training and validation loss curves"""
    plt.figure(figsize=(12, 6))
    
    # Plot total loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot component losses
    plt.subplot(1, 2, 2)
    if 'output_steps_loss' in history.history:
        plt.plot(history.history['output_steps_loss'], label='Training Steps Loss')
        plt.plot(history.history['val_output_steps_loss'], label='Validation Steps Loss')
    if 'output_success_loss' in history.history:
        plt.plot(history.history['output_success_loss'], label='Training Success Loss')
        plt.plot(history.history['val_output_success_loss'], label='Validation Success Loss')
    plt.title('Component Losses')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Loss curve saved to: {save_path}")


# ==========================================================
# ä¸»ç¨‹åºï¼ˆæ— éœ€ parse_argsï¼‰
# ==========================================================

def main_train():
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
    set_seed(SEED)
    
    # åˆå§‹åŒ–wandb
    wandb.init(
        project="word-difficulty-prediction",
        name="lstm-model-run",
        config={
            "model_type": "LSTM",
            "look_back": LOOK_BACK,
            "batch_size": BATCH_SIZE,
            "epochs": EPOCHS,
            "learning_rate": LEARNING_RATE,
            "lstm_units": LSTM_UNITS,
            "dropout_rate": DROPOUT_RATE,
            "embedding_dim": EMBEDDING_DIM,
            "seed": SEED
        }
    )
    
    ensure_dirs()

    # 1. æ•°æ®è¯»å–
    train_df = safe_read_csv(TRAIN_FILE, usecols=["Game", "Trial", "Username", "target"])
    val_df = safe_read_csv(VAL_FILE, usecols=["Game", "Trial", "Username", "target"])
    test_df = safe_read_csv(TEST_FILE, usecols=["Game", "Trial", "Username", "target"])

    # 2. éš¾åº¦/ç”¨æˆ·æ°´å¹³
    diff_map = {}
    user_map = {}
    if os.path.exists(DIFFICULTY_FILE):
        ddf = pd.read_csv(DIFFICULTY_FILE)
        diff_map = dict(zip(ddf["word"], ddf["avg_trial"]))
    if os.path.exists(PLAYER_FILE):
        pdf = pd.read_csv(PLAYER_FILE)
        user_map = dict(zip(pdf["Username"], pdf["avg_trial"]))

    # 3. Tokenizerï¼ˆtrain-onlyï¼‰
    tokenizer = fit_tokenizer(train_df)

    train_df = attach_features(train_df, tokenizer, diff_map, user_map)
    val_df = attach_features(val_df, tokenizer, diff_map, user_map)
    test_df = attach_features(test_df, tokenizer, diff_map, user_map)

    # 4. Build histories
    hist_train = build_history(train_df)
    hist_val = build_history(val_df)
    hist_test = build_history(test_df)

    # 5. Sliding samples
    X_train = create_samples(hist_train, LOOK_BACK)
    X_val = create_samples(hist_val, LOOK_BACK)
    X_test = create_samples(hist_test, LOOK_BACK)

    print(f"Train={len(X_train[0])}, Val={len(X_val[0])}, Test={len(X_test[0])}")

    vocab_size = len(tokenizer.word_index) + 1

    # 6. Model
    model = build_model(LOOK_BACK, vocab_size)
    model.summary()

    # 7. TF dataset
    train_ds = tf.data.Dataset.from_tensor_slices((
        {
            "input_history": X_train[0],
            "input_difficulty": X_train[1],
            "input_word_id": X_train[2],
            "input_user_bias": X_train[3]
        },
        {
            "output_steps": X_train[4],
            "output_success": X_train[5]
        }
    )).shuffle(20000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    val_ds = tf.data.Dataset.from_tensor_slices((
        {
            "input_history": X_val[0],
            "input_difficulty": X_val[1],
            "input_word_id": X_val[2],
            "input_user_bias": X_val[3]
        },
        {
            "output_steps": X_val[4],
            "output_success": X_val[5]
        }
    )).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    # 8. è®­ç»ƒ
    early = EarlyStopping(monitor="val_loss", patience=PATIENCE, restore_best_weights=True)
    train_history = model.fit(
        train_ds, 
        validation_data=val_ds, 
        epochs=EPOCHS, 
        callbacks=[early, WandbCallback(save_model=False, log_model=False)]
    )
    
    # ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±æ›²çº¿
    loss_curve_path = "visualization/LSTM_loss_curve.png"
    plot_loss(train_history, loss_curve_path)

    model.save(MODEL_SAVE_PATH)
    print(f"Model saved to {MODEL_SAVE_PATH}")

    print("\n=== Validation ===")
    val_mae, val_rmse, val_acc, val_auc = evaluate_model(model, X_val)
    
    # è®°å½•éªŒè¯é›†æŒ‡æ ‡åˆ°wandb
    wandb.log({
        "val_mae": val_mae,
        "val_rmse": val_rmse,
        "val_accuracy": val_acc,
        "val_auc": val_auc
    })
    
    # ç»˜åˆ¶éªŒè¯é›†AUCæ›²çº¿
    val_pred_steps, val_pred_prob = model.predict({
        "input_history": X_val[0],
        "input_difficulty": X_val[1],
        "input_word_id": X_val[2],
        "input_user_bias": X_val[3]
    }, batch_size=1024, verbose=0)
    val_roc_curve_path = "visualization/LSTM_validation_roc_curve.png"
    plot_roc_curve(X_val[5], val_pred_prob.flatten(), val_roc_curve_path)

    print("\n=== Test ===")
    test_mae, test_rmse, test_acc, test_auc = evaluate_model(model, X_test)
    
    # è®°å½•æµ‹è¯•é›†æŒ‡æ ‡åˆ°wandb
    wandb.log({
        "test_mae": test_mae,
        "test_rmse": test_rmse,
        "test_accuracy": test_acc,
        "test_auc": test_auc
    })
    
    # ç»˜åˆ¶æµ‹è¯•é›†AUCæ›²çº¿
    test_pred_steps, test_pred_prob = model.predict({
        "input_history": X_test[0],
        "input_difficulty": X_test[1],
        "input_word_id": X_test[2],
        "input_user_bias": X_test[3]
    }, batch_size=1024, verbose=0)
    test_roc_curve_path = "visualization/LSTM_test_roc_curve.png"
    plot_roc_curve(X_test[5], test_pred_prob.flatten(), test_roc_curve_path)

    # --------------------------------------------------------
    # ç”Ÿæˆå¤§å‹è¯¯å·®ç»Ÿè®¡
    # --------------------------------------------------------
    val_pred_steps, _ = model.predict({
        "input_history": X_val[0],
        "input_difficulty": X_val[1],
        "input_word_id": X_val[2],
        "input_user_bias": X_val[3]
    }, batch_size=1024, verbose=0)
    val_pred_steps = val_pred_steps.flatten()
    val_large_error_rate = compute_large_error_rate(X_val[4], np.clip(val_pred_steps, 0, 7), LARGE_ERROR_THRESHOLD)

    test_pred_steps, _ = model.predict({
        "input_history": X_test[0],
        "input_difficulty": X_test[1],
        "input_word_id": X_test[2],
        "input_user_bias": X_test[3]
    }, batch_size=1024, verbose=0)
    test_pred_steps = test_pred_steps.flatten()
    test_large_error_rate = compute_large_error_rate(X_test[4], np.clip(test_pred_steps, 0, 7), LARGE_ERROR_THRESHOLD)

    # --------------------------------------------------------
    # æ ¼å¼åŒ–æŠ¥å‘Š
    # --------------------------------------------------------
    report = f"""
========================================
 LSTM Model Validation and Test Report 
========================================
---- Validation Set Metrics ----
1. Mean Absolute Error (MAE)    : {val_mae:.4f}
2. Root Mean Squared Error (RMSE)     : {val_rmse:.4f}
3. Win/Loss Prediction Accuracy        : {val_acc:.3%}
4. Area Under ROC Curve (AUC)   : {val_auc:.4f}
5. Large Error Rate (>{LARGE_ERROR_THRESHOLD} steps)  : {val_large_error_rate:.3%}

---- Test Set Metrics ----
1. Mean Absolute Error (MAE)    : {test_mae:.4f}
2. Root Mean Squared Error (RMSE)     : {test_rmse:.4f}
3. Win/Loss Prediction Accuracy        : {test_acc:.3%}
4. Area Under ROC Curve (AUC)   : {test_auc:.4f}
5. Large Error Rate (>{LARGE_ERROR_THRESHOLD} steps)  : {test_large_error_rate:.3%}
========================================
"""

    # --------------------------------------------------------
    # ä¿å­˜åˆ°æ–‡ä»¶
    # --------------------------------------------------------
    with open(REPORT_SAVE_PATH, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nğŸ“„ Report saved to: {REPORT_SAVE_PATH}")
    print(report)
    
    # è®°å½•å¤§å‹è¯¯å·®ç‡åˆ°wandb
    wandb.log({
        "val_large_error_rate": val_large_error_rate,
        "test_large_error_rate": test_large_error_rate
    })
    
    # ç»“æŸwandbè¿è¡Œ
    wandb.finish()


# é¢„æµ‹æ¨¡å¼ï¼ˆæŒ‰éœ€å¯ç”¨ï¼‰
def main_predict(user_id):
    if not os.path.exists(MODEL_SAVE_PATH):
        raise FileNotFoundError("è¯·å…ˆè®­ç»ƒæ¨¡å‹ã€‚")

    model = tf.keras.models.load_model(MODEL_SAVE_PATH)

    tokenizer = load_tokenizer()

    df = safe_read_csv(TRAIN_FILE, usecols=["Game", "Trial", "Username", "target"])
    diff_map = {}
    user_map = {}
    if os.path.exists(DIFFICULTY_FILE):
        ddf = pd.read_csv(DIFFICULTY_FILE)
        diff_map = dict(zip(ddf["word"], ddf["avg_trial"]))
    if os.path.exists(PLAYER_FILE):
        pdf = pd.read_csv(PLAYER_FILE)
        user_map = dict(zip(pdf["Username"], pdf["avg_trial"]))

    df = attach_features(df, tokenizer, diff_map, user_map)
    hist = build_history(df)

    if user_id not in hist:
        print(f"ç”¨æˆ· {user_id} æ— è®°å½•")
        return

    events = hist[user_id]
    if len(events) < 1:
        print("å†å²ä¸è¶³")
        return

    # å‡†å¤‡è¾“å…¥
    if len(events) < LOOK_BACK:
        avg = np.mean([e[0] for e in events])
        pad = [(avg, 4.0, 0, 4.0)] * (LOOK_BACK - len(events))
        window = pad + events
    else:
        window = events[-LOOK_BACK:]

    trials = np.array([w[0] for w in window], np.float32)
    seq = np.stack([trials/7.0, np.full_like(trials, np.std(trials)/7.0)], axis=1)
    seq = seq.reshape(1, LOOK_BACK, 2)

    last = events[-1]
    diff = np.array([[last[1] / 7.0]], np.float32)
    wid = np.array([[last[2]]], np.int32)
    bias = np.array([[last[3] / 7.0]], np.float32)

    p_steps, p_prob = model.predict({
        "input_history": seq,
        "input_difficulty": diff,
        "input_word_id": wid,
        "input_user_bias": bias
    }, verbose=0)

    print(f"é¢„æµ‹æ­¥æ•°: {float(np.clip(p_steps, 0, 6.99)):.2f}")
    print(f"æˆåŠŸæ¦‚ç‡: {float(p_prob):.3f}")


# ==========================================================
# ç¨‹åºå¯åŠ¨å…¥å£ï¼ˆåªéœ€è¦æ”¹è¿™å‡ è¡Œå³å¯æ§åˆ¶ train æˆ– predictï¼‰
# ==========================================================
if __name__ == "__main__":
    # æ£€æµ‹æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™ç›´æ¥è¿›è¡Œé¢„æµ‹
    if os.path.exists(MODEL_SAVE_PATH) and os.path.exists(TOKENIZER_PATH):
        print("æ£€æµ‹åˆ°å·²å­˜åœ¨æ¨¡å‹ï¼Œç›´æ¥è¿›è¡Œé¢„æµ‹...")
        USER_TO_PREDICT = "Alice"  # è‹¥è¦é¢„æµ‹ï¼Œå¡«ç”¨æˆ· ID
        main_predict(USER_TO_PREDICT)
    else:
        # è¿è¡Œæ¨¡å¼
        RUN_MODE = "train"     # "train" æˆ– "predict"
        USER_TO_PREDICT = "Alice"  # è‹¥è¦é¢„æµ‹ï¼Œå¡«ç”¨æˆ· ID
        
        if RUN_MODE == "train":
            print("æœªæ£€æµ‹åˆ°æ¨¡å‹æˆ–tokenizerï¼Œå¼€å§‹è®­ç»ƒæ¨¡å‹...")
            main_train()
        else:
            main_predict(USER_TO_PREDICT)