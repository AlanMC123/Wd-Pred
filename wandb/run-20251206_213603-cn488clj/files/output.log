Train=340169, Val=29283, Test=6230
WARNING:tensorflow:From D:\Python\Python312\Lib\site-packages\keras\src\backend\tensorflow\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.
[1mModel: "functional_2"[0m
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m [0m[1mLayer (type)              [0m[1m [0mâ”ƒ[1m [0m[1mOutput Shape          [0m[1m [0mâ”ƒ[1m [0m[1m      Param #[0m[1m [0mâ”ƒ[1m [0m[1mConnected to           [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_history ([38;5;33mInputLayer[0m) â”‚ ([38;5;45mNone[0m, [38;5;34m5[0m, [38;5;34m2[0m)           â”‚             [38;5;34m0[0m â”‚ -                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_guess_sequence       â”‚ ([38;5;45mNone[0m, [38;5;34m6[0m, [38;5;34m8[0m)           â”‚             [38;5;34m0[0m â”‚ -                       â”‚
â”‚ ([38;5;33mInputLayer[0m)               â”‚                        â”‚               â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense ([38;5;33mDense[0m)              â”‚ ([38;5;45mNone[0m, [38;5;34m5[0m, [38;5;34m16[0m)          â”‚            [38;5;34m48[0m â”‚ input_history[[38;5;34m0[0m][[38;5;34m0[0m]     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 ([38;5;33mDense[0m)            â”‚ ([38;5;45mNone[0m, [38;5;34m6[0m, [38;5;34m16[0m)          â”‚           [38;5;34m144[0m â”‚ input_guess_sequence[[38;5;34m0[0mâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add ([38;5;33mAdd[0m)                  â”‚ ([38;5;45mNone[0m, [38;5;34m5[0m, [38;5;34m16[0m)          â”‚             [38;5;34m0[0m â”‚ dense[[38;5;34m0[0m][[38;5;34m0[0m]             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 ([38;5;33mAdd[0m)                â”‚ ([38;5;45mNone[0m, [38;5;34m6[0m, [38;5;34m16[0m)          â”‚             [38;5;34m0[0m â”‚ dense_3[[38;5;34m0[0m][[38;5;34m0[0m]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ transformer_block          â”‚ ([38;5;45mNone[0m, [38;5;34m5[0m, [38;5;34m16[0m)          â”‚         [38;5;34m7,056[0m â”‚ add[[38;5;34m0[0m][[38;5;34m0[0m]               â”‚
â”‚ ([38;5;33mTransformerBlock[0m)         â”‚                        â”‚               â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_word_id ([38;5;33mInputLayer[0m) â”‚ ([38;5;45mNone[0m, [38;5;34m1[0m)              â”‚             [38;5;34m0[0m â”‚ -                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ transformer_block_1        â”‚ ([38;5;45mNone[0m, [38;5;34m6[0m, [38;5;34m16[0m)          â”‚         [38;5;34m7,056[0m â”‚ add_1[[38;5;34m0[0m][[38;5;34m0[0m]             â”‚
â”‚ ([38;5;33mTransformerBlock[0m)         â”‚                        â”‚               â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooling1d   â”‚ ([38;5;45mNone[0m, [38;5;34m16[0m)             â”‚             [38;5;34m0[0m â”‚ transformer_block[[38;5;34m0[0m][[38;5;34m0[0m] â”‚
â”‚ ([38;5;33mGlobalAveragePooling1D[0m)   â”‚                        â”‚               â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ embedding_2 ([38;5;33mEmbedding[0m)    â”‚ ([38;5;45mNone[0m, [38;5;34m1[0m, [38;5;34m16[0m)          â”‚         [38;5;34m5,152[0m â”‚ input_word_id[[38;5;34m0[0m][[38;5;34m0[0m]     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_user_bias            â”‚ ([38;5;45mNone[0m, [38;5;34m1[0m)              â”‚             [38;5;34m0[0m â”‚ -                       â”‚
â”‚ ([38;5;33mInputLayer[0m)               â”‚                        â”‚               â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooling1d_1 â”‚ ([38;5;45mNone[0m, [38;5;34m16[0m)             â”‚             [38;5;34m0[0m â”‚ transformer_block_1[[38;5;34m0[0m]â€¦ â”‚
â”‚ ([38;5;33mGlobalAveragePooling1D[0m)   â”‚                        â”‚               â”‚                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_3 ([38;5;33mDropout[0m)        â”‚ ([38;5;45mNone[0m, [38;5;34m16[0m)             â”‚             [38;5;34m0[0m â”‚ global_average_poolingâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten ([38;5;33mFlatten[0m)          â”‚ ([38;5;45mNone[0m, [38;5;34m16[0m)             â”‚             [38;5;34m0[0m â”‚ embedding_2[[38;5;34m0[0m][[38;5;34m0[0m]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_6 ([38;5;33mDense[0m)            â”‚ ([38;5;45mNone[0m, [38;5;34m16[0m)             â”‚            [38;5;34m32[0m â”‚ input_user_bias[[38;5;34m0[0m][[38;5;34m0[0m]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_7 ([38;5;33mDropout[0m)        â”‚ ([38;5;45mNone[0m, [38;5;34m16[0m)             â”‚             [38;5;34m0[0m â”‚ global_average_poolingâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate ([38;5;33mConcatenate[0m)  â”‚ ([38;5;45mNone[0m, [38;5;34m64[0m)             â”‚             [38;5;34m0[0m â”‚ dropout_3[[38;5;34m0[0m][[38;5;34m0[0m],        â”‚
â”‚                            â”‚                        â”‚               â”‚ flatten[[38;5;34m0[0m][[38;5;34m0[0m],          â”‚
â”‚                            â”‚                        â”‚               â”‚ dense_6[[38;5;34m0[0m][[38;5;34m0[0m],          â”‚
â”‚                            â”‚                        â”‚               â”‚ dropout_7[[38;5;34m0[0m][[38;5;34m0[0m]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_7 ([38;5;33mDense[0m)            â”‚ ([38;5;45mNone[0m, [38;5;34m64[0m)             â”‚         [38;5;34m4,160[0m â”‚ concatenate[[38;5;34m0[0m][[38;5;34m0[0m]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_8 ([38;5;33mDropout[0m)        â”‚ ([38;5;45mNone[0m, [38;5;34m64[0m)             â”‚             [38;5;34m0[0m â”‚ dense_7[[38;5;34m0[0m][[38;5;34m0[0m]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_9 ([38;5;33mDense[0m)            â”‚ ([38;5;45mNone[0m, [38;5;34m64[0m)             â”‚         [38;5;34m4,160[0m â”‚ dropout_8[[38;5;34m0[0m][[38;5;34m0[0m]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_10 ([38;5;33mDropout[0m)       â”‚ ([38;5;45mNone[0m, [38;5;34m64[0m)             â”‚             [38;5;34m0[0m â”‚ dense_9[[38;5;34m0[0m][[38;5;34m0[0m]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_8 ([38;5;33mDense[0m)            â”‚ ([38;5;45mNone[0m, [38;5;34m32[0m)             â”‚         [38;5;34m2,080[0m â”‚ dropout_8[[38;5;34m0[0m][[38;5;34m0[0m]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_10 ([38;5;33mDense[0m)           â”‚ ([38;5;45mNone[0m, [38;5;34m32[0m)             â”‚         [38;5;34m2,080[0m â”‚ dropout_10[[38;5;34m0[0m][[38;5;34m0[0m]        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_9 ([38;5;33mDropout[0m)        â”‚ ([38;5;45mNone[0m, [38;5;34m32[0m)             â”‚             [38;5;34m0[0m â”‚ dense_8[[38;5;34m0[0m][[38;5;34m0[0m]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_11 ([38;5;33mDropout[0m)       â”‚ ([38;5;45mNone[0m, [38;5;34m32[0m)             â”‚             [38;5;34m0[0m â”‚ dense_10[[38;5;34m0[0m][[38;5;34m0[0m]          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ output_steps ([38;5;33mDense[0m)       â”‚ ([38;5;45mNone[0m, [38;5;34m1[0m)              â”‚            [38;5;34m33[0m â”‚ dropout_9[[38;5;34m0[0m][[38;5;34m0[0m]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ output_success ([38;5;33mDense[0m)     â”‚ ([38;5;45mNone[0m, [38;5;34m1[0m)              â”‚            [38;5;34m33[0m â”‚ dropout_11[[38;5;34m0[0m][[38;5;34m0[0m]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m Total params: [0m[38;5;34m32,034[0m (125.13 KB)
[1m Trainable params: [0m[38;5;34m32,034[0m (125.13 KB)
[1m Non-trainable params: [0m[38;5;34m0[0m (0.00 B)
Epoch 1/30
[1m333/333[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m80s[0m 229ms/step - loss: 1.5847 - output_steps_loss: 6.1791 - output_success_accuracy: 0.8368 - output_success_loss: 0.3472 - val_loss: 0.4032 - val_output_steps_loss: 1.3686 - val_output_success_accuracy: 0.9724 - val_output_success_loss: 0.1301
Epoch 2/30
[1m333/333[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m67s[0m 201ms/step - loss: 0.7828 - output_steps_loss: 3.0111 - output_success_accuracy: 0.9650 - output_success_loss: 0.1807 - val_loss: 0.3790 - val_output_steps_loss: 1.2454 - val_output_success_accuracy: 0.9724 - val_output_success_loss: 0.1305
Epoch 3/30
[1m333/333[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m72s[0m 215ms/step - loss: 0.6885 - output_steps_loss: 2.5529 - output_success_accuracy: 0.9650 - output_success_loss: 0.1777 - val_loss: 0.3966 - val_output_steps_loss: 1.3196 - val_output_success_accuracy: 0.9724 - val_output_success_loss: 0.1333
Epoch 4/30
[1m333/333[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m71s[0m 214ms/step - loss: 0.6363 - output_steps_loss: 2.3001 - output_success_accuracy: 0.9650 - output_success_loss: 0.1760 - val_loss: 0.4067 - val_output_steps_loss: 1.3660 - val_output_success_accuracy: 0.9724 - val_output_success_loss: 0.1341
Epoch 5/30
[1m333/333[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m70s[0m 211ms/step - loss: 0.6033 - output_steps_loss: 2.1497 - output_success_accuracy: 0.9650 - output_success_loss: 0.1733 - val_loss: 0.3915 - val_output_steps_loss: 1.3035 - val_output_success_accuracy: 0.9724 - val_output_success_loss: 0.1313
Total Loss curve saved to: visualization\Transformer_total_loss_curve.png
Steps Loss curve saved to: visualization\Transformer_steps_loss_curve.png
Success Loss curve saved to: visualization\Transformer_success_loss_curve.png
Model saved to models/transformer/transformer_model.keras

=== Validation ===
[1m29/29[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 81ms/step
MAE=0.9003, RMSE=1.1154, naive_ACC=0.9724, best_threshold=-0.9823, ACC_best_thresh=0.9729, AUC=0.7837, corr(pred_prob,y)=-0.1608
âš ï¸ Note: pred_prob appears inverted relative to labels. evaluate_model used -pred_prob for AUC/ACC calculation.
âš ï¸ ROC plotting: detected better AUC with -prob for Model, using -prob for ROC plot.
ROC curve saved to: visualization/Transformer_validation_roc_curve.png
Scatter plot saved to: visualization/Transformer_validation_scatter.png

=== Test ===
[1m7/7[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 70ms/step
MAE=0.8673, RMSE=1.0891, naive_ACC=0.9722, best_threshold=-0.9816, ACC_best_thresh=0.9727, AUC=0.8009, corr(pred_prob,y)=-0.1737
âš ï¸ Note: pred_prob appears inverted relative to labels. evaluate_model used -pred_prob for AUC/ACC calculation.
âš ï¸ ROC plotting: detected better AUC with -prob for Model, using -prob for ROC plot.
ROC curve saved to: visualization/Transformer_test_roc_curve.png
Scatter plot saved to: visualization/Transformer_test_scatter.png

ğŸ“„ Report saved to: outputs/transformer_output.txt

========================================
 Transformer Guess Sequence Model Report
========================================
---- Validation Set Metrics ----
1. Mean Absolute Error (MAE)    : 0.9003
2. Root Mean Squared Error (RMSE)     : 1.1154
3. Win/Loss Prediction Accuracy        : 97.285%
4. Area Under ROC Curve (AUC)   : 0.7837
5. Large Error Rate (>1.5 steps)  : 18.820%

---- Test Set Metrics ----
1. Mean Absolute Error (MAE)    : 0.8673
2. Root Mean Squared Error (RMSE)     : 1.0891
3. Win/Loss Prediction Accuracy        : 97.271%
4. Area Under ROC Curve (AUC)   : 0.8009
5. Large Error Rate (>1.5 steps)  : 17.159%
========================================
