Step 1: è¯»å–æ•°æ®å¹¶æ„å»ºå››ç‰¹å¾...
f:\Codes\Wd-Pred\transformer_prediction.py:99: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  history_map = df.groupby('Username').apply(
Step 2: æ„å»ºå››è¾“å…¥æ ·æœ¬...
æ•°æ®é›†åˆ’åˆ†ï¼šè®­ç»ƒé›† 2770743, éªŒè¯é›† 395820, æµ‹è¯•é›† 791642
âœ… æ•°æ®åŠ è½½ä¼˜åŒ–å·²åº”ç”¨ (cache + prefetch)
Step 3: æ„å»ºTransformerç¥ç»ç½‘ç»œ (Vocab=321, Layers=3)...
WARNING:tensorflow:From D:\Python\Python312\Lib\site-packages\keras\src\backend\tensorflow\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

D:\Python\Python312\Lib\site-packages\keras\src\layers\core\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.
  warnings.warn(
âœ… æ¨¡å‹ç¼–è¯‘å®Œæˆï¼Œä½¿ç”¨Focal Loss (gamma=2.0, alpha=0.25)
Step 4: å¼€å§‹è®­ç»ƒ (Epochs=10, Batch=4096, Patience=5)...
æç¤º: å½“å‰ä½¿ç”¨CPUè®­ç»ƒï¼Œé€Ÿåº¦å¯èƒ½è¾ƒæ…¢ã€‚å»ºè®®ä½¿ç”¨æ”¯æŒCUDAçš„GPUä»¥è·å¾—æ˜¾è‘—åŠ é€Ÿã€‚
Epoch 1/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m121s[0m 173ms/step - loss: 2.2214 - output_steps_loss: 2.2087 - output_success_accuracy: 0.9627 - output_success_loss: 0.0239 - val_loss: 1.2638 - val_output_steps_loss: 1.2539 - val_output_success_accuracy: 0.9664 - val_output_success_loss: 0.0198
Epoch 2/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m132s[0m 195ms/step - loss: 1.3160 - output_steps_loss: 1.3068 - output_success_accuracy: 0.9643 - output_success_loss: 0.0183 - val_loss: 1.2475 - val_output_steps_loss: 1.2391 - val_output_success_accuracy: 0.9667 - val_output_success_loss: 0.0170
Epoch 3/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m163s[0m 241ms/step - loss: 1.2710 - output_steps_loss: 1.2623 - output_success_accuracy: 0.9616 - output_success_loss: 0.0173 - val_loss: 1.2454 - val_output_steps_loss: 1.2371 - val_output_success_accuracy: 0.9651 - val_output_success_loss: 0.0168
Epoch 4/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m130s[0m 193ms/step - loss: 1.2588 - output_steps_loss: 1.2502 - output_success_accuracy: 0.9611 - output_success_loss: 0.0170 - val_loss: 1.2435 - val_output_steps_loss: 1.2353 - val_output_success_accuracy: 0.9651 - val_output_success_loss: 0.0167
Epoch 5/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m108s[0m 159ms/step - loss: 1.2551 - output_steps_loss: 1.2467 - output_success_accuracy: 0.9611 - output_success_loss: 0.0169 - val_loss: 1.2433 - val_output_steps_loss: 1.2351 - val_output_success_accuracy: 0.9652 - val_output_success_loss: 0.0167
Epoch 6/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m139s[0m 205ms/step - loss: 1.2526 - output_steps_loss: 1.2441 - output_success_accuracy: 0.9611 - output_success_loss: 0.0168 - val_loss: 1.2430 - val_output_steps_loss: 1.2348 - val_output_success_accuracy: 0.9650 - val_output_success_loss: 0.0166
Epoch 7/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m146s[0m 215ms/step - loss: 1.2512 - output_steps_loss: 1.2428 - output_success_accuracy: 0.9608 - output_success_loss: 0.0167 - val_loss: 1.2422 - val_output_steps_loss: 1.2341 - val_output_success_accuracy: 0.9646 - val_output_success_loss: 0.0164
Epoch 8/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m160s[0m 237ms/step - loss: 1.2498 - output_steps_loss: 1.2415 - output_success_accuracy: 0.9606 - output_success_loss: 0.0166 - val_loss: 1.2419 - val_output_steps_loss: 1.2338 - val_output_success_accuracy: 0.9652 - val_output_success_loss: 0.0164
Epoch 9/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m158s[0m 233ms/step - loss: 1.2486 - output_steps_loss: 1.2403 - output_success_accuracy: 0.9612 - output_success_loss: 0.0165 - val_loss: 1.2421 - val_output_steps_loss: 1.2340 - val_output_success_accuracy: 0.9658 - val_output_success_loss: 0.0164
Epoch 10/10
[1m677/677[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m149s[0m 220ms/step - loss: 1.2470 - output_steps_loss: 1.2388 - output_success_accuracy: 0.9615 - output_success_loss: 0.0164 - val_loss: 1.2416 - val_output_steps_loss: 1.2335 - val_output_success_accuracy: 0.9659 - val_output_success_loss: 0.0163
âœ… Lossæ›²çº¿å·²ä¿å­˜è‡³: visualization\Transformer_loss_curve.png

âœ… æ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ°: models/Transformer_Model.keras

Step 4: å¼€å§‹æ‰¹é‡é¢„æµ‹ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡...
[1m97/97[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 93ms/step

Step 4: å¼€å§‹æ‰¹é‡é¢„æµ‹ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡...
[1m194/194[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m21s[0m 106ms/step

========================================
  Transformeræ¨¡å‹éªŒè¯å’Œæµ‹è¯•æŠ¥å‘Š
========================================
---- éªŒè¯é›†æŒ‡æ ‡ ----
1. å¹³å‡æ­¥æ•°è¯¯å·® (MAE)    : 0.9048
2. å‡æ–¹æ ¹è¯¯å·® (RMSE)     : 1.1106
3. èƒœè´Ÿé¢„æµ‹å‡†ç¡®ç‡        : 96.590%
4. ROCæ›²çº¿ä¸‹é¢ç§¯ (AUC)   : 0.8625
5. å¤§å‹è¯¯å·®ç‡ (>1.5æ­¥)  : 18.010%

---- æµ‹è¯•é›†æŒ‡æ ‡ ----
1. å¹³å‡æ­¥æ•°è¯¯å·® (MAE)    : 0.9052
2. å‡æ–¹æ ¹è¯¯å·® (RMSE)     : 1.1104
3. èƒœè´Ÿé¢„æµ‹å‡†ç¡®ç‡        : 96.594%
4. ROCæ›²çº¿ä¸‹é¢ç§¯ (AUC)   : 0.8646
5. å¤§å‹è¯¯å·®ç‡ (>1.5æ­¥)  : 17.973%
========================================


Step 5: å¯åŠ¨å›æµ‹éªŒè¯æŠ½æ ·æŠ¥å‘Š (æ ·æœ¬æ•°=10000, è¾“å‡ºè‡³ output.txt)...
------------------------------------------------------------
User ID    | Bias  | Diff  | Real  | Pred  | Err   | Status
------------------------------------------------------------
568482     | 4.27  | 4.54  | 5    | 4.55  | 0.45  | âœ…
17262      | 5.87  | 4.44  | 5    | 5.84  | 0.84  | âœ…
844339     | 3.55  | 3.52  | 2    | 2.96  | 0.96  | âœ…
879525     | 4.89  | 4.61  | 6    | 5.08  | 0.92  | âœ…
648086     | 4.50  | 4.41  | 3    | 4.62  | 1.62  | âŒ
710898     | 4.29  | 4.04  | 5    | 4.04  | 0.96  | âœ…
808626     | 3.67  | 4.55  | 3    | 3.90  | 0.90  | âœ…
805167     | 4.11  | 4.35  | 5    | 4.25  | 0.75  | âœ…
847322     | 3.78  | 3.77  | 3    | 3.37  | 0.37  | âœ…
785071     | 3.56  | 3.82  | 3    | 3.13  | 0.13  | âœ…
... (å…¶ä½™ 9990 æ¡çœç•¥)

âœ… æŠ½æ ·æŠ¥å‘Šå·²æˆåŠŸå¯¼å‡ºè‡³ outputs/transformer_output.txt æ–‡ä»¶ã€‚
âœ… é¢„æµ‹è¶‹åŠ¿å›¾å·²ä¿å­˜è‡³: visualization\Transformer_prediction_trends.png
