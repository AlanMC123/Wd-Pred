ğŸ“Š å¼€å§‹æ•°æ®å¤„ç†...
Step 1: è¯»å–æ•°æ®å¹¶æ„å»ºå››ç‰¹å¾...
âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œè¯æ±‡è¡¨å¤§å°: 321
Step 2: æ„å»ºå››è¾“å…¥æ ·æœ¬...
f:\Codes\Wd-Pred\LSTM_train.py:81: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  history_map = df.groupby('Username').apply(
âœ… æ•°æ®é›†æ„å»ºå®Œæˆï¼Œæ ·æœ¬æ•°é‡: 3958205
âœ… è®­ç»ƒé›†å¤§å°: 3166564, éªŒè¯é›†å¤§å°: 791641
Step 3: æ„å»ºå››è¾“å…¥LSTMç¥ç»ç½‘ç»œ (Vocab=321)...
  LSTMé…ç½®: 2å±‚, æ¯å±‚64ä¸ªå•å…ƒ, Dropout=0.2
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
 input_history (InputLayer)  [(None, 8, 2)]               0         []
 lstm (LSTM)                 (None, 8, 64)                17152     ['input_history[0][0]']
 dropout (Dropout)           (None, 8, 64)                0         ['lstm[0][0]']
 input_word_id (InputLayer)  [(None, 1)]                  0         []
 lstm_1 (LSTM)               (None, 64)                   33024     ['dropout[0][0]']
 input_difficulty (InputLay  [(None, 1)]                  0         []
 er)
 embedding (Embedding)       (None, 1, 64)                20544     ['input_word_id[0][0]']
 input_user_bias (InputLaye  [(None, 1)]                  0         []
 r)
 dropout_1 (Dropout)         (None, 64)                   0         ['lstm_1[0][0]']
 dense (Dense)               (None, 16)                   32        ['input_difficulty[0][0]']
 flatten (Flatten)           (None, 64)                   0         ['embedding[0][0]']
 dense_1 (Dense)             (None, 16)                   32        ['input_user_bias[0][0]']
 concatenate (Concatenate)   (None, 160)                  0         ['dropout_1[0][0]',
                                                                     'dense[0][0]',
                                                                     'flatten[0][0]',
                                                                     'dense_1[0][0]']
 dense_2 (Dense)             (None, 64)                   10304     ['concatenate[0][0]']
 dropout_2 (Dropout)         (None, 64)                   0         ['dense_2[0][0]']
 dense_3 (Dense)             (None, 32)                   2080      ['dropout_2[0][0]']
 dense_4 (Dense)             (None, 16)                   1040      ['dropout_2[0][0]']
 output_steps (Dense)        (None, 1)                    33        ['dense_3[0][0]']
 output_success (Dense)      (None, 1)                    17        ['dense_4[0][0]']
==================================================================================================
Total params: 84258 (329.13 KB)
Trainable params: 84258 (329.13 KB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
ğŸš€ å¼€å§‹è®­ç»ƒ (Epochs=15, Batch=2048)...
Epoch 1/15




















































































1547/1547 [==============================] - 184s 118ms/step - loss: 1.5398 - output_steps_loss: 1.4652 - output_success_loss: 0.1493 - output_success_accuracy: 0.9632 - val_loss: 1.6772 - val_output_steps_loss: 1.6208 - val_output_success_loss: 0.1128 - val_output_success_accuracy: 0.9669
Epoch 2/15






















































































1547/1547 [==============================] - 188s 122ms/step - loss: 1.3087 - output_steps_loss: 1.2516 - output_success_loss: 0.1142 - output_success_accuracy: 0.9672 - val_loss: 1.7815 - val_output_steps_loss: 1.7265 - val_output_success_loss: 0.1101 - val_output_success_accuracy: 0.9676
Epoch 3/15




